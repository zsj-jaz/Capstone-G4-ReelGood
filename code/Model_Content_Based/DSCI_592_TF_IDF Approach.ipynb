{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54ddae59-c776-44bf-b0c0-08bc9ce05bb6",
   "metadata": {},
   "source": [
    "# DSCI 592: Capstone Project\n",
    "# Reel Good Movie Recommender System (Group 4)\n",
    "- By Alireza Hatami"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02bf0b50-591b-45cb-906a-b20776ccb1df",
   "metadata": {},
   "source": [
    "## TF-IDF-Based Content Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930fc95-dcc6-4112-84e5-dc783b8d9b75",
   "metadata": {},
   "source": [
    "### 1. Loading `model_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2876d664-1195-424f-8bdb-28b3440c2bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from joblib import Parallel, delayed\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e99d861-6e6d-4dbc-8003-d94e6bbf8331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/cleaned_data.csv')\n",
    "model_df = pd.read_csv('model_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5c7f8-c21c-428e-bc4f-75fbe5c12d3c",
   "metadata": {},
   "source": [
    "### 2. Vectorizing Textual Data (title, director_clean, actors_clean, overview columns using TFIDF):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "381b7ae5-607b-4817-8576-3063aa7493e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_and_save(df, column_name, output_prefix, save_dir='./tfidf'):\n",
    "    \"\"\"\n",
    "    Applies TF-IDF to a specific column in the dataframe and saves both\n",
    "    the resulting sparse matrix and the vectorizer.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column_name (str): Column to apply TF-IDF on.\n",
    "        output_prefix (str): Filename prefix (e.g., 'title' → tfidf_title.npz).\n",
    "        save_dir (str): Folder to save the output files.\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    print(f\"Processing TF-IDF for '{column_name}'...\")\n",
    "\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(df[column_name])\n",
    "\n",
    "    # Save matrix\n",
    "    matrix_path = os.path.join(save_dir, f'tfidf_{output_prefix}.npz')\n",
    "    sparse.save_npz(matrix_path, tfidf_matrix)\n",
    "\n",
    "    # Save vectorizer\n",
    "    vectorizer_path = os.path.join(save_dir, f'vectorizer_{output_prefix}.pkl')\n",
    "    joblib.dump(vectorizer, vectorizer_path)\n",
    "\n",
    "    print(f\"Saved: {matrix_path} and {vectorizer_path} | Shape: {tfidf_matrix.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cc21f5a8-09a9-4728-b0d4-0e42ca440c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF for 'title'...\n",
      "Saved: ./tfidf\\tfidf_title.npz and ./tfidf\\vectorizer_title.pkl | Shape: (44880, 45863)\n"
     ]
    }
   ],
   "source": [
    "tfidf_and_save(model_df, 'title', 'title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "688b04a6-5480-4a3b-bdbc-7091f340b040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF for 'director_clean'...\n",
      "Saved: ./tfidf\\tfidf_director.npz and ./tfidf\\vectorizer_director.pkl | Shape: (44880, 18558)\n"
     ]
    }
   ],
   "source": [
    "tfidf_and_save(model_df, 'director_clean', 'director')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7c3cbe40-a91c-426a-8926-5b73bbe9c894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF for 'actors_clean'...\n",
      "Saved: ./tfidf\\tfidf_actors.npz and ./tfidf\\vectorizer_actors.pkl | Shape: (44880, 49543)\n"
     ]
    }
   ],
   "source": [
    "tfidf_and_save(model_df, 'actors_clean', 'actors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "86621043-3c89-42ea-9806-f4e3b4befdf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing TF-IDF for 'overview'...\n",
      "Saved: ./tfidf\\tfidf_overview.npz and ./tfidf\\vectorizer_overview.pkl | Shape: (44880, 76166)\n"
     ]
    }
   ],
   "source": [
    "tfidf_and_save(model_df, 'overview', 'overview')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4046cc9-4b66-422e-9926-21326c793c90",
   "metadata": {},
   "source": [
    "We can then load the embeddings for use later with:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e507484-8f44-4d78-98c2-a24003ef394d",
   "metadata": {},
   "source": [
    "### 3. Load + Stack Everything Together Later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc55529-c0d0-4071-9f49-71209eb572da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final matrix shape: (44880, 190172)\n"
     ]
    }
   ],
   "source": [
    "# Load TF-IDF matrices\n",
    "tfidf_title = sparse.load_npz('./tfidf/tfidf_title.npz')\n",
    "tfidf_director = sparse.load_npz('./tfidf/tfidf_director.npz')\n",
    "tfidf_actors = sparse.load_npz('./tfidf/tfidf_actors.npz')\n",
    "tfidf_overview = sparse.load_npz('./tfidf/tfidf_overview.npz')\n",
    "\n",
    "# Load one-hot encodings\n",
    "language_encoded = pd.read_csv('language_encoded.csv') # From DSCI_592_Additional_Preprocessing.ipynb\n",
    "genre_df = pd.read_csv('genre_df.csv') # From DSCI_592_Additional_Preprocessing.ipynb\n",
    "\n",
    "# Convert to sparse\n",
    "lang_sparse = sparse.csr_matrix(language_encoded.values)\n",
    "genre_sparse = sparse.csr_matrix(genre_df.values)\n",
    "year_scaled = sparse.csr_matrix(model_df[['year_scaled']].values)\n",
    "\n",
    "# Combine everything\n",
    "final_matrix = sparse.hstack([\n",
    "    tfidf_title,\n",
    "    tfidf_director,\n",
    "    tfidf_actors,\n",
    "    tfidf_overview,\n",
    "    genre_sparse,\n",
    "    lang_sparse,\n",
    "    year_scaled\n",
    "])\n",
    "\n",
    "print(\"Final matrix shape:\", final_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7c91cf-cae1-44f5-8088-d1b23b5b7cb5",
   "metadata": {},
   "source": [
    "#### 3.1 Saving + Loading the Sparse Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc04c00-4009-45bb-afb4-f9cff1bfc502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save sparse matrix\n",
    "# sparse.save_npz('final_matrix_tfidf.npz', final_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28682a92-1da0-44f8-af3b-33018f4981a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the sparse matrix\n",
    "final_matrix = sparse.load_npz('final_matrix_tfidf.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bcbafa-19bc-443d-9fb4-b2b084554afa",
   "metadata": {},
   "source": [
    "### 4. Find Similar Movies:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7295b94-40d6-4775-98c7-695d9bb46317",
   "metadata": {},
   "source": [
    "Here, we:\n",
    "- Only compute similarity between one movie vs. all others (not all-pairs, which is way too expensive).\n",
    "\n",
    "- Keep everything sparse.\n",
    "\n",
    "- Retrieve top N most similar movies (excluding the movie itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3da69ad-fd1e-4035-a131-8fc99bf9262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_movies(title, matrix, model_df, top_n=10):\n",
    "    \"\"\"\n",
    "    Finds top N similar movies and returns key metadata.\n",
    "\n",
    "    Args:\n",
    "        title (str): Movie title with underscores (e.g., 'Toy_Story').\n",
    "        matrix (csr_matrix): Sparse feature matrix.\n",
    "        model_df (pd.DataFrame): DataFrame with movie metadata.\n",
    "        top_n (int): Number of similar movies to return.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Top N similar movies with metadata.\n",
    "    \"\"\"\n",
    "    idx = model_df[model_df['title'] == title].index[0]\n",
    "    sim_scores = cosine_similarity(matrix[idx], matrix).flatten()\n",
    "    sim_scores[idx] = -1  # Exclude the input movie itself\n",
    "    \n",
    "    # sim_scores = -euclidean_distances(matrix[idx], matrix).flatten() # For euclidean distance\n",
    "    # sim_scores[idx] = np.min(sim_scores) - 1\n",
    "    \n",
    "    top_indices = np.argsort(sim_scores)[-top_n:][::-1]\n",
    "\n",
    "    # Select relevant rows *first*, then assign the score\n",
    "    result_df = model_df.loc[top_indices, [\n",
    "        'title', 'director_clean', 'actors_clean', 'genres_clean', 'overview', 'original_language'\n",
    "    ]].copy()\n",
    "\n",
    "    result_df['score'] = sim_scores[top_indices]\n",
    "\n",
    "    result_df['year'] = result_df['title'].apply(\n",
    "        lambda t: df[df['title'] == t]['year'].values[0] if len(df[df['title'] == t]) > 0 else 'N/A'\n",
    "    )\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc231735-7c19-4be5-9c9f-b5eb09ee4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_movie_recommendations(similar_df, max_overview_len=300):\n",
    "    \"\"\"\n",
    "    Pretty prints movie recommendations with director, actors, and a short overview.\n",
    "\n",
    "    Args:\n",
    "        similar_df (pd.DataFrame): DataFrame from get_similar_movies().\n",
    "        max_overview_len (int): Max number of characters to show for overview.\n",
    "    \"\"\"   \n",
    "    for i, row in similar_df.iterrows():\n",
    "        print(f\"{row['title']} ({row['year']}) — Score: {row['score']:.4f}\")\n",
    "        print(f\"   Director: {row['director_clean']}\")\n",
    "        print(f\"   Actors: {row['actors_clean']}\")\n",
    "        print(f\"   Genres: {row['genres_clean']}\")\n",
    "        print(f\"   Overview: {row['overview'][:max_overview_len]}...\\n\")\n",
    "        print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bb181069-da8b-42f8-9127-7c46586e670b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy Story 2 (1999) — Score: 0.7789\n",
      "   Director: John_Lasseter\n",
      "   Actors: Tom_Hanks Tim_Allen Joan_Cusack\n",
      "   Genres: ['Animation', 'Comedy', 'Family']\n",
      "   Overview: Andy heads off to Cowboy Camp, leaving his toys to their own devices. Things shift into high gear when an obsessive toy collector named Al McWhiggen, owner of Al's Toy Barn kidnaps Woody. Andy's toys mount a daring rescue mission, Buzz Lightyear meets his match and Woody has to decide where he and h...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Toy Story 3 (2010) — Score: 0.6744\n",
      "   Director: Lee_Unkrich\n",
      "   Actors: Tom_Hanks Tim_Allen Ned_Beatty\n",
      "   Genres: ['Animation', 'Family', 'Comedy']\n",
      "   Overview: Woody, Buzz, and the rest of Andy's toys haven't been played with in years. With Andy about to go to college, the gang find themselves accidentally left at a nefarious day care center. The toys must band together to escape and return home to Andy....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Cars 2 (2011) — Score: 0.6236\n",
      "   Director: John_Lasseter\n",
      "   Actors: Owen_Wilson Larry_the_Cable_Guy Michael_Caine\n",
      "   Genres: ['Animation', 'Family', 'Adventure', 'Comedy']\n",
      "   Overview: Star race car Lightning McQueen and his pal Mater head overseas to compete in the World Grand Prix race. But the road to the championship becomes rocky as Mater gets caught up in an intriguing adventure of his own: international espionage....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Cars (2006) — Score: 0.6226\n",
      "   Director: John_Lasseter\n",
      "   Actors: Owen_Wilson Paul_Newman Bonnie_Hunt\n",
      "   Genres: ['Animation', 'Adventure', 'Comedy', 'Family']\n",
      "   Overview: Lightning McQueen, a hotshot rookie race car driven to succeed, discovers that life is about the journey, not the finish line, when he finds himself unexpectedly detoured in the sleepy Route 66 town of Radiator Springs. On route across the country to the big Piston Cup Championship in California to ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "A Bug's Life (1998) — Score: 0.6224\n",
      "   Director: John_Lasseter\n",
      "   Actors: Kevin_Spacey Julia_Louis-Dreyfus Hayden_Panettiere\n",
      "   Genres: ['Adventure', 'Animation', 'Comedy', 'Family']\n",
      "   Overview: On behalf of \"oppressed bugs everywhere,\" an inventive ant named Flik hires a troupe of warrior bugs to defend his bustling colony from a horde of freeloading grasshoppers led by the evil-minded Hopper....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Toy Story of Terror! (2013) — Score: 0.6111\n",
      "   Director: Angus_MacLane\n",
      "   Actors: Tom_Hanks Tim_Allen Kristen_Schaal\n",
      "   Genres: ['Animation', 'Comedy', 'Family']\n",
      "   Overview: What starts out as a fun road trip for the Toy Story gang takes an unexpected turn for the worse when the trip detours to a roadside motel. After one of the toys goes missing, the others find themselves caught up in a mysterious sequence of events that must be solved before they all suffer the same ...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Partysaurus Rex (2012) — Score: 0.5794\n",
      "   Director: Mark_A._Walsh\n",
      "   Actors: Tom_Hanks Tim_Allen Wallace_Shawn\n",
      "   Genres: ['Animation', 'Comedy', 'Family', 'Fantasy']\n",
      "   Overview: When Rex finds himself left behind in the bathroom, he puts his limbs to use by getting a bath going for a bunch of new toy friends....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Mater and the Ghostlight (2006) — Score: 0.5763\n",
      "   Director: John_Lasseter\n",
      "   Actors: Larry_the_Cable_Guy Owen_Wilson Michael_Wallis\n",
      "   Genres: ['Animation', 'Family']\n",
      "   Overview: Mater, the rusty but trusty tow truck from Cars, spends a day in Radiator Springs playing scary pranks on his fellow townsfolk. That night at Flo's V8 Café, the Sheriff tells the story of the legend of the Ghostlight, and as everyone races home Mater is left alone primed for a good old-fashioned sca...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Free Birds (2013) — Score: 0.5509\n",
      "   Director: Jimmy_Hayward\n",
      "   Actors: Owen_Wilson Woody_Harrelson Amy_Poehler\n",
      "   Genres: ['Animation', 'Comedy', 'Family']\n",
      "   Overview: In this irreverent, hilarious, adventurous buddy comedy for audiences of all ages, directed by Jimmy Hayward (Horton Hears a Who!), two turkeys from opposite sides of the tracks must put aside their differences and team up to travel back in time to change the course of history - and get turkey off t...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Monsters, Inc. (2001) — Score: 0.5474\n",
      "   Director: Pete_Docter\n",
      "   Actors: John_Goodman Billy_Crystal Mary_Gibbs\n",
      "   Genres: ['Animation', 'Comedy', 'Family']\n",
      "   Overview: James Sullivan and Mike Wazowski are monsters, they earn their living scaring children and are the best in the business... even though they're more afraid of the children than they are of them. When a child accidentally enters their world, James and Mike suddenly find that kids are not to be afraid ...\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "similar = get_similar_movies('Toy Story', final_matrix, model_df, top_n=10)\n",
    "print_movie_recommendations(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bde1ee6-e97b-4ce7-a13e-342a764014e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Matrix Reloaded (2003) — Score: 0.6050\n",
      "   Director: Lilly_Wachowski\n",
      "   Actors: Keanu_Reeves Carrie-Anne_Moss Laurence_Fishburne\n",
      "   Genres: ['Adventure', 'Action', 'Thriller', 'Science', 'Fiction']\n",
      "   Overview: Six months after the events depicted in The Matrix, Neo has proved to be a good omen for the free humans, as more and more humans are being freed from the matrix and brought to Zion, the one and only stronghold of the Resistance.  Neo himself has discovered his superpowers including super speed, abi...\n",
      "\n",
      "------------------------------------------------------------\n",
      "The Matrix Revolutions (2003) — Score: 0.5933\n",
      "   Director: Lilly_Wachowski\n",
      "   Actors: Keanu_Reeves Laurence_Fishburne Carrie-Anne_Moss\n",
      "   Genres: ['Adventure', 'Action', 'Thriller', 'Science', 'Fiction']\n",
      "   Overview: The human city of Zion defends itself against the massive invasion of the machines as Neo fights to end the war at another front while also opposing the rogue Agent Smith....\n",
      "\n",
      "------------------------------------------------------------\n",
      "A.P.E.X. (1994) — Score: 0.5745\n",
      "   Director: Phillip_J._Roth\n",
      "   Actors: Richard_Keats Mitchell_Cox Lisa_Ann_Russell\n",
      "   Genres: ['Science', 'Fiction', 'Action']\n",
      "   Overview: A time-travel experiment in which a robot probe is sent from the year 2073 to the year 1973 goes terribly wrong thrusting one of the project scientists,into a plague ravaged alternate time-line whose war weary inhabitants are locked in a constant battle with killer robots from the future....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Red Planet (2000) — Score: 0.5743\n",
      "   Director: Antony_Hoffman\n",
      "   Actors: Val_Kilmer Carrie-Anne_Moss Benjamin_Bratt\n",
      "   Genres: ['Thriller', 'Action', 'Science', 'Fiction']\n",
      "   Overview: Astronauts search for solutions to save a dying Earth by searching on Mars, only to have the mission go terribly awry....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Five (1951) — Score: 0.5584\n",
      "   Director: Arch_Oboler\n",
      "   Actors: William_Phipps Susan_Douglas James_Anderson\n",
      "   Genres: ['Action', 'Science', 'Fiction']\n",
      "   Overview: The world is destroyed in a nuclear holocaust. Only five Americans survive, including a pregnant woman, a neo-Nazi, a black man and a bank clerk. The five fight each other, fall in love, and act really depressed a lot....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Paradox (2010) — Score: 0.5548\n",
      "   Director: Michael_Hurst\n",
      "   Actors: Zoë_Bell Adam_Huss Malik_Yoba\n",
      "   Genres: ['Action', 'Science', 'Fiction']\n",
      "   Overview: A group of scientists are experimenting with time travel, and they manage to send one of their group ahead in time one hour. But when he comes back, he tells them that they’ll all be dead within the next hour unless they shut the machine down....\n",
      "\n",
      "------------------------------------------------------------\n",
      "The Colony (2013) — Score: 0.5540\n",
      "   Director: Jeff_Renfroe\n",
      "   Actors: Laurence_Fishburne Kevin_Zegers Bill_Paxton\n",
      "   Genres: ['Action', 'Science', 'Fiction', 'Horror']\n",
      "   Overview: Forced underground by the next ice age, a struggling outpost of survivors must fight to preserve humanity against a threat even more savage than nature....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Parallels (2015) — Score: 0.5539\n",
      "   Director: Christopher_Leone\n",
      "   Actors: Mark_Hapka Jessica_Rothe Eric_Jungmann\n",
      "   Genres: ['Science', 'Fiction', 'Action']\n",
      "   Overview: An underground MMA fighter must confront his sister and his past in an adventure through parallel universes...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Lawnmower Man 2: Beyond Cyberspace (1996) — Score: 0.5534\n",
      "   Director: Farhad_Mann\n",
      "   Actors: Patrick_Bergin Matt_Frewer Austin_O'Brien\n",
      "   Genres: ['Action', 'Science', 'Fiction']\n",
      "   Overview: Jobe is resuscitated by Jonathan Walker. He wants Jobe to create a special computer chip that would connect all the computers in the world into one network, which Walker would control and use. But what Walker doesn't realize is a group of teenage hackers are on to him and out to stop his plan....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Rakka (2017) — Score: 0.5530\n",
      "   Director: Neill_Blomkamp\n",
      "   Actors: Sigourney_Weaver Eugene_Khumbanyiwa Robert_Hobbs\n",
      "   Genres: ['Action', 'Science', 'Fiction']\n",
      "   Overview: \"Rakka\" is the story of broken humanity following the invasion of a technologically superior alien species. Bleak harrowing and unrelenting, the humans we meet must find enough courage to go on fighting....\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "similar_matrix = get_similar_movies('The Matrix', final_matrix, model_df, top_n=10)\n",
    "print_movie_recommendations(similar_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f17d8237-749a-4d5f-8701-0ab268b8a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home Alone 2: Lost in New York (1992) — Score: 0.6307\n",
      "   Director: Chris_Columbus\n",
      "   Actors: Macaulay_Culkin Joe_Pesci Catherine_O'Hara\n",
      "   Genres: ['Comedy', 'Family', 'Adventure', 'Crime']\n",
      "   Overview: Instead of flying to Florida with his folks, Kevin ends up alone in New York, where he gets a hotel room with his dad's credit card—despite problems from a clerk and meddling bellboy. But when Kevin runs into his old nemeses, the Wet Bandits, he's determined to foil their plans to rob a toy store on...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Mrs. Doubtfire (1993) — Score: 0.5716\n",
      "   Director: Chris_Columbus\n",
      "   Actors: Robin_Williams Sally_Field Pierce_Brosnan\n",
      "   Genres: ['Comedy', 'Drama', 'Family']\n",
      "   Overview: Loving but irresponsible dad Daniel Hillard, estranged from his exasperated spouse, is crushed by a court order allowing only weekly visits with his kids. When Daniel learns his ex needs a housekeeper, he gets the job -- disguised as an English nanny. Soon he becomes not only his children's best pal...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Home Alone: The Holiday Heist (2012) — Score: 0.5511\n",
      "   Director: Peter_Hewitt\n",
      "   Actors: Jodelle_Ferland Christian_Martyn Ellie_Harvie\n",
      "   Genres: ['Comedy', 'Crime', 'Family']\n",
      "   Overview: 8-year-old Finn who is terrified to learn his family is relocating from sunny California to Maine in the scariest house he has ever seen! Convinced that his new house is haunted, Finn sets up a series of elaborate traps to catch the “ghost” in action. Left home alone with his sister while their pare...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Bill (2015) — Score: 0.5228\n",
      "   Director: Richard_Bracewell\n",
      "   Actors: Mathew_Baynton Simon_Farnaby Martha_Howe-Douglas\n",
      "   Genres: ['Comedy', 'Family']\n",
      "   Overview: What really happened during Shakespeare's 'Lost Years'? Hopeless lute player Bill Shakespeare leaves his home to follow his dream....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Gone Fishin' (1997) — Score: 0.5226\n",
      "   Director: Christopher_Cain\n",
      "   Actors: Joe_Pesci Danny_Glover Rosanna_Arquette\n",
      "   Genres: ['Comedy', 'Family']\n",
      "   Overview: Two fishing fanatics get in trouble when their fishing boat gets stolen while on a trip....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Ri¢hie Ri¢h (1994) — Score: 0.5214\n",
      "   Director: Donald_Petrie\n",
      "   Actors: Macaulay_Culkin John_Larroquette Edward_Herrmann\n",
      "   Genres: ['Comedy', 'Family']\n",
      "   Overview: Billionaire heir Richie Rich has it all, including Reggie Jackson as a batting coach and Claudia Schiffer as a personal trainer -- but no playmates. What's more, scoundrel Laurence Van Dough is scheming to take over the family empire. Uh-oh! Enter faithful butler Cadbury to save the day....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Frankenweenie (2012) — Score: 0.5154\n",
      "   Director: Tim_Burton\n",
      "   Actors: Shelley_Duvall Daniel_Stern Barret_Oliver\n",
      "   Genres: ['Comedy', 'Family']\n",
      "   Overview: When young Victor's pet dog Sparky (who stars in Victor's home-made monster movies) is hit by a car, Victor decides to bring him back to life the only way he knows how. But when the bolt-necked \"monster\" wreaks havoc and terror in the hearts of Victor's neighbors, he has to convince them (and his pa...\n",
      "\n",
      "------------------------------------------------------------\n",
      "Nine Months (1995) — Score: 0.5121\n",
      "   Director: Chris_Columbus\n",
      "   Actors: Hugh_Grant Julianne_Moore Tom_Arnold\n",
      "   Genres: ['Comedy']\n",
      "   Overview: When he finds out his longtime girlfriend is pregnant, a commitment-phobe realizes he might have to change his lifestyle for better or much, much worse....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Alone For Christmas (2013) — Score: 0.5004\n",
      "   Director: Joseph_J._Lawson\n",
      "   Actors: Kevin_Sorbo David_DeLuise Kim_Little\n",
      "   Genres: ['Comedy', 'Family']\n",
      "   Overview: When a family visits Grandma's house on Christmas Eve, they leave their dog at home alone. And when burglars try to take the presents from under the tree, the dog must use every trick it knows to stop them....\n",
      "\n",
      "------------------------------------------------------------\n",
      "Getting Even with Dad (1994) — Score: 0.4926\n",
      "   Director: Howard_Deutch\n",
      "   Actors: Macaulay_Culkin Ted_Danson Glenne_Headly\n",
      "   Genres: ['Family', 'Comedy', 'Crime']\n",
      "   Overview: Ray, an ex-con and widower, is planning a coin heist with two accomplices to help him to buy his own bakery. However, he doesn't expect his son Timmy, who was living with Ray's sister, to show up at the house right in the middle of planning. Timmy is ignored and Ray and his buddies pull off the heis...\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "similar_Home_Alone = get_similar_movies('Home Alone', final_matrix, model_df, top_n=10)\n",
    "print_movie_recommendations(similar_Home_Alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43e37b8-19f7-496a-baeb-10f849a4b6f0",
   "metadata": {},
   "source": [
    "### 5. Performance Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31879e8c-020a-48c6-863f-bd54dfd39398",
   "metadata": {},
   "source": [
    "We built item-to-item content-based filtering, where we measure similarity between movies based on their metadata and content (e.g., title, genres, actors, etc.), and recommend similar movies to a given movie. This is one valid form of content-based recommendation, especially useful when:\n",
    "- We have no or minimal user interaction data\n",
    "- We want to support queries like “Show me movies like Toy Story”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dcb16f-5734-4766-8286-3e4c31ace73e",
   "metadata": {},
   "source": [
    "#### 5.1. `is_relevant()` Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcfe143d-0be5-4dcb-b372-d0a6984d677b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(query_row, candidate_row):\n",
    "    # 1. Language must match\n",
    "    if query_row['original_language'] != candidate_row['original_language']:\n",
    "        return False\n",
    "\n",
    "    # 2. Director match\n",
    "    if query_row['director_clean'] == candidate_row['director_clean']:\n",
    "        return True\n",
    "\n",
    "    # 3. At least 2 genres match\n",
    "    query_genres = set(eval(query_row['genres_clean']))\n",
    "    candidate_genres = set(eval(candidate_row['genres_clean']))\n",
    "    if len(query_genres.intersection(candidate_genres)) >= 2:\n",
    "        return True\n",
    "\n",
    "    # 4. At least 1 actor match\n",
    "    query_actors = set(query_row['actors_clean'].split())\n",
    "    candidate_actors = set(candidate_row['actors_clean'].split())\n",
    "    if len(query_actors.intersection(candidate_actors)) >= 1:\n",
    "        return True\n",
    "\n",
    "    # None matched\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb41c328-2350-4aa3-ac1a-d63b98dd0672",
   "metadata": {},
   "source": [
    "#### 5.2. Calculating `Precision@K`\n",
    "\n",
    "How many of the top-K recommended movies are actually relevant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8055e1d0-9997-42c3-a5e4-2909fce49dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_at_k(query_title, model_df, matrix, k=10):\n",
    "    \"\"\"\n",
    "    Computes Precision@K for a given movie by comparing its top K similar movies\n",
    "    against a relevance function.\n",
    "\n",
    "    Args:\n",
    "        query_title (str): The title of the query movie.\n",
    "        model_df (pd.DataFrame): DataFrame containing movie metadata.\n",
    "        matrix (csr_matrix): Sparse matrix of movie feature vectors.\n",
    "        k (int): Number of top recommendations to consider (default is 10).\n",
    "\n",
    "    Returns:\n",
    "        float: Precision@K score, i.e., the proportion of top K recommendations\n",
    "               that are considered relevant.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = model_df[model_df['title'] == query_title].index[0]\n",
    "    query_row = model_df.iloc[idx]\n",
    "\n",
    "    recommended = get_similar_movies(query_title, matrix, model_df, top_n=k)\n",
    "\n",
    "    relevant_count = 0\n",
    "    for _, candidate_row in recommended.iterrows():\n",
    "        if is_relevant(query_row, candidate_row):\n",
    "            relevant_count += 1\n",
    "\n",
    "    precision = relevant_count / k\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53848ab5-6fed-45ff-8497-a1fec047632a",
   "metadata": {},
   "source": [
    "#### 5.3. Calculating `Recall@K`\n",
    "\n",
    "Out of all relevant movies in the full catalog, how many were retrieved in top K?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16ffc56-cc16-47ef-aefb-bda3a19cb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_at_k(query_title, model_df, matrix, k=10):\n",
    "    \"\"\"\n",
    "    Computes Recall@K for a given movie by comparing its top K similar movies\n",
    "    against the full set of relevant movies in the dataset.\n",
    "\n",
    "    Args:\n",
    "        query_title (str): The title of the query movie.\n",
    "        model_df (pd.DataFrame): DataFrame containing movie metadata.\n",
    "        matrix (csr_matrix): Sparse matrix of movie feature vectors.\n",
    "        k (int): Number of top recommendations to consider (default is 10).\n",
    "\n",
    "    Returns:\n",
    "        float: Recall@K score, i.e., the proportion of all relevant movies\n",
    "               that appear in the top K recommendations.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = model_df[model_df['title'] == query_title].index[0]\n",
    "    query_row = model_df.iloc[idx]\n",
    "\n",
    "    # Find all relevant movies in dataset\n",
    "    relevant_total = 0\n",
    "    for _, candidate_row in model_df.iterrows():\n",
    "        if is_relevant(query_row, candidate_row):\n",
    "            relevant_total += 1\n",
    "\n",
    "    # Prevent division by zero\n",
    "    if relevant_total == 0:\n",
    "        return 0.0\n",
    "\n",
    "    # Get top-k recommended\n",
    "    recommended = get_similar_movies(query_title, matrix, model_df, top_n=k)\n",
    "\n",
    "    relevant_in_topk = 0\n",
    "    for _, candidate_row in recommended.iterrows():\n",
    "        if is_relevant(query_row, candidate_row):\n",
    "            relevant_in_topk += 1\n",
    "\n",
    "    recall = relevant_in_topk / relevant_total\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34cf795-8eec-432c-a77e-651b036497c2",
   "metadata": {},
   "source": [
    "#### 5.4. `MRR@K (Mean Reciprocal Rank)`\n",
    "\n",
    "\"How early did I show the user something they liked?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cad2ad3a-2352-43c0-a5d0-fb29853b7f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_at_k(query_title, model_df, matrix, k=10):\n",
    "    \"\"\"\n",
    "    Computes the Mean Reciprocal Rank at K (MRR@K) for a given query movie.\n",
    "\n",
    "    MRR@K measures how early the first relevant item appears in the top K\n",
    "    recommendations. It returns the reciprocal of the rank of the first \n",
    "    relevant recommendation, or 0 if no relevant item is found.\n",
    "\n",
    "    Args:\n",
    "        query_title (str): The title of the query movie.\n",
    "        model_df (pd.DataFrame): DataFrame containing movie metadata.\n",
    "        matrix (csr_matrix): Sparse matrix of movie feature vectors.\n",
    "        k (int): Number of top recommendations to consider (default is 10).\n",
    "\n",
    "    Returns:\n",
    "        float: Reciprocal rank of the first relevant recommendation, or 0.0\n",
    "               if no relevant item is found in the top K.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = model_df[model_df['title'] == query_title].index[0]\n",
    "    query_row = model_df.iloc[idx]\n",
    "\n",
    "    recommended = get_similar_movies(query_title, matrix, model_df, top_n=k)\n",
    "\n",
    "    for rank, (_, candidate_row) in enumerate(recommended.iterrows(), start=1):\n",
    "        if is_relevant(query_row, candidate_row):\n",
    "            return 1 / rank  # Reciprocal Rank\n",
    "\n",
    "    return 0.0  # No relevant item found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf540534-bd64-4fed-8d92-40cbcf42f2fd",
   "metadata": {},
   "source": [
    "#### 5.5. `evaluate_multiple_queries()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "933ae984-a47f-4bc2-88a9-3095bac60aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def evaluate_multiple_queries(model_df, matrix, num_samples=100, k=10, seed=42):\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a recommendation system over multiple randomly \n",
    "    selected query movies using Precision@K, Recall@K, and MRR@K metrics.\n",
    "\n",
    "    Args:\n",
    "        model_df (pd.DataFrame): DataFrame containing movie metadata.\n",
    "        matrix (csr_matrix): Sparse matrix of movie feature vectors used for similarity computation.\n",
    "        num_samples (int): Number of random movies to sample for evaluation (default is 100).\n",
    "        k (int): Number of top recommendations to consider for each metric (default is 10).\n",
    "        seed (int): Random seed for reproducibility (default is 42).\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - mean_precision (float): Mean Precision@K over all valid samples.\n",
    "            - mean_recall (float): Mean Recall@K over all valid samples.\n",
    "            - mean_mrr (float): Mean Mean Reciprocal Rank@K over all valid samples.\n",
    "    \n",
    "    Notes:\n",
    "        - Movies that raise errors during evaluation (e.g., missing data) are skipped.\n",
    "        - Metrics are averaged only over successfully evaluated samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)  # for reproducibility\n",
    "\n",
    "    # Randomly pick num_samples titles\n",
    "    sample_titles = random.sample(list(model_df['title']), num_samples)\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    mrrs = []\n",
    "\n",
    "    for title in sample_titles:\n",
    "        try:\n",
    "            precision = precision_at_k(title, model_df, matrix, k)\n",
    "            recall = recall_at_k(title, model_df, matrix, k)\n",
    "            mrr = mrr_at_k(title, model_df, matrix, k)\n",
    "\n",
    "            precisions.append(precision)\n",
    "            recalls.append(recall)\n",
    "            mrrs.append(mrr)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping '{title}' due to error: {e}\")\n",
    "            continue\n",
    "\n",
    "    # Calculate means\n",
    "    mean_precision = sum(precisions) / len(precisions) if precisions else 0\n",
    "    mean_recall = sum(recalls) / len(recalls) if recalls else 0\n",
    "    mean_mrr = sum(mrrs) / len(mrrs) if mrrs else 0\n",
    "\n",
    "    print(f\"\\nEvaluation Results over {len(precisions)} movies:\")\n",
    "    print(f\"➡Mean Precision@{k}: {mean_precision:.4f}\")\n",
    "    print(f\"➡Mean Recall@{k}: {mean_recall:.4f}\")\n",
    "    print(f\"➡Mean MRR@{k}: {mean_mrr:.4f}\")\n",
    "\n",
    "    return mean_precision, mean_recall, mean_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5533bb-10fd-4bfa-ad82-ee3a5e289a63",
   "metadata": {},
   "source": [
    "##### 5.5.1 Evaluatation `@5`, `@10` and `@20` using Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc3ea282-4e81-43d4-aee8-ec8d5a3525b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results over 100 movies:\n",
      "➡Mean Precision@5: 0.8120\n",
      "➡Mean Recall@5: 0.0820\n",
      "➡Mean MRR@5: 0.9137\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 100 random movies, top-5 recommendations\n",
    "mean_precision, mean_recall, mean_mrr = evaluate_multiple_queries(model_df, final_matrix, num_samples=100, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c215b08-d46b-42ca-9e53-7939c53fb4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results over 100 movies:\n",
      "➡Mean Precision@10: 0.7710\n",
      "➡Mean Recall@10: 0.1063\n",
      "➡Mean MRR@10: 0.9137\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 100 random movies, top-10 recommendations\n",
    "mean_precision, mean_recall, mean_mrr = evaluate_multiple_queries(model_df, final_matrix, num_samples=100, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61570c3b-e3e3-45d2-bbfb-39c349bc17ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results over 100 movies:\n",
      "➡Mean Precision@20: 0.7235\n",
      "➡Mean Recall@20: 0.1293\n",
      "➡Mean MRR@20: 0.9137\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 100 random movies, top-20 recommendations\n",
    "mean_precision, mean_recall, mean_mrr = evaluate_multiple_queries(model_df, final_matrix, num_samples=100, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4e8047-7969-465f-bebe-c9854477d079",
   "metadata": {},
   "source": [
    "##### 5.5.2 Evaluatation `@5`, `@10` and `@20` using Euclidean Disance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f35bfa8-83cc-4b96-bea9-624d973624de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results over 100 movies:\n",
      "➡Mean Precision@5: 0.7500\n",
      "➡Mean Recall@5: 0.0609\n",
      "➡Mean MRR@5: 0.8320\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 100 random movies, top-5 recommendations\n",
    "mean_precision, mean_recall, mean_mrr = evaluate_multiple_queries(model_df, final_matrix, num_samples=100, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a294597b-597b-423f-a933-a1919cbbddb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results over 100 movies:\n",
      "➡Mean Precision@10: 0.7280\n",
      "➡Mean Recall@10: 0.0824\n",
      "➡Mean MRR@10: 0.8374\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 100 random movies, top-10 recommendations\n",
    "mean_precision, mean_recall, mean_mrr = evaluate_multiple_queries(model_df, final_matrix, num_samples=100, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aef466e-7c26-47c2-8f43-ca990d917570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Results over 100 movies:\n",
      "➡Mean Precision@20: 0.7030\n",
      "➡Mean Recall@20: 0.1069\n",
      "➡Mean MRR@20: 0.8387\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on 100 random movies, top-20 recommendations\n",
    "mean_precision, mean_recall, mean_mrr = evaluate_multiple_queries(model_df, final_matrix, num_samples=100, k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2bd74d-1c8f-464b-9814-fd5b7c4d6d56",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "Cosine Work Better for TF-IDF, why?\n",
    "\n",
    "- Cosine is designed to measure angle/direction, not magnitude — perfect for normalized sparse vectors\n",
    "- Magnitude is not meaningful in TF-IDF\n",
    "- Euclidean penalizes documents that are longer or shorter, even if the word composition is similar\n",
    "\n",
    "So, Cosine similarity is significantly more effective than Euclidean distance for TF-IDF-based movie recommendation, especially for ranking relevant items early (as shown by higher MRR, Precision, and Recall)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec445407-0dda-4249-9dcb-7e5d58da6e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the Results\n",
    "k_values = [5, 10, 20]\n",
    "\n",
    "cosine_metrics_tfidf = {\n",
    "    'P': [0.8120, 0.7710, 0.7235],\n",
    "    'R': [0.0820, 0.1063, 0.1293],\n",
    "    'MRR': [0.9137, 0.9137, 0.9137]\n",
    "}\n",
    "\n",
    "euclidean_metrics_tfidf = {\n",
    "    'P': [0.7500, 0.7280, 0.7030],\n",
    "    'R': [0.0609, 0.0824, 0.1069],\n",
    "    'MRR': [0.8320, 0.8374, 0.8387]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70f2a952-fcb0-4b16-90e4-51b69cbd5adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(cosine_metrics, euclidean_metrics, k_values):\n",
    "    \"\"\"\n",
    "    Plot side-by-side comparison of Precision@K, Recall@K, and MRR@K\n",
    "    between cosine similarity and Euclidean distance.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cosine_metrics : dict\n",
    "        Dictionary containing 'P', 'R', and 'MRR' scores for each K using cosine similarity.\n",
    "        Example: {'P': [...], 'R': [...], 'MRR': [...]}\n",
    "\n",
    "    euclidean_metrics : dict\n",
    "        Dictionary containing 'P', 'R', and 'MRR' scores for each K using Euclidean distance.\n",
    "        Example: {'P': [...], 'R': [...], 'MRR': [...]}\n",
    "\n",
    "    k_values : list of int\n",
    "        List of K values used for evaluation (e.g., [5, 10, 20]).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "        Displays a matplotlib figure with 3 subplots comparing the metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    metrics = ['P', 'R', 'MRR']\n",
    "    labels = ['Precision@K', 'Recall@K', 'MRR@K']\n",
    "    \n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(1, 3, i + 1)\n",
    "        plt.plot(k_values, cosine_metrics[metric], marker='o', label='Cosine')\n",
    "        plt.plot(k_values, euclidean_metrics[metric], marker='s', label='Euclidean')\n",
    "        plt.title(labels[i])\n",
    "        plt.xlabel('K')\n",
    "        plt.ylabel('Score')\n",
    "        plt.xticks(k_values)\n",
    "        plt.ylim(0, 1.05)\n",
    "        plt.grid(True)\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee6b7558-070b-4ebb-9181-6d72ffb4f4ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_comparison(cosine_metrics_tfidf, euclidean_metrics_tfidf, k_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbe1fd7-ba93-4002-a448-541ae19474bd",
   "metadata": {},
   "source": [
    "Since we have 45000 movies, it will take a lot of computational power to calculate precision on every single item (we have about 45000 movies). So, the strategy to evaluate all movies includes:\n",
    "\n",
    "1. Batch Processing: Split the movie dataset into manageable chunks (e.g., 100–500 movies per batch) and process each batch independently.\n",
    "2. Caching Expensive Computations: Reuse similarity vectors instead of re-computing. If you’re always calculating similarity between a single movie and all others, keep the sparse matrix in memory, and slice once per iteration.\n",
    "3. Avoid DataFrame Iteration\n",
    "4. Instead of iterating rows with `.iterrows()`, vectorize operations wherever possible or minimize expensive loops.\n",
    "5. Use `joblib.Parallel` to Leverage All CPU Cores: This significantly reduces compute time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026c7d6c-05e2-4f25-a9bc-18c235a28aaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing movies 0 to 100...\n",
      "Saved batch 0–100 in 20.4 sec. Total done: 100\n",
      "Processing movies 100 to 200...\n",
      "Saved batch 100–200 in 17.3 sec. Total done: 200\n",
      "Processing movies 200 to 300...\n",
      "Saved batch 200–300 in 18.2 sec. Total done: 300\n",
      "Processing movies 300 to 400...\n",
      "Saved batch 300–400 in 16.5 sec. Total done: 400\n",
      "Processing movies 400 to 500...\n",
      "Saved batch 400–500 in 16.2 sec. Total done: 500\n",
      "Processing movies 500 to 600...\n",
      "Saved batch 500–600 in 17.0 sec. Total done: 600\n",
      "Processing movies 600 to 700...\n",
      "Saved batch 600–700 in 16.1 sec. Total done: 700\n",
      "Processing movies 700 to 800...\n",
      "Saved batch 700–800 in 17.7 sec. Total done: 800\n",
      "Processing movies 800 to 900...\n",
      "Saved batch 800–900 in 16.9 sec. Total done: 900\n",
      "Processing movies 900 to 1000...\n",
      "Saved batch 900–1000 in 17.6 sec. Total done: 1000\n",
      "Processing movies 1000 to 1100...\n",
      "Saved batch 1000–1100 in 17.4 sec. Total done: 1100\n",
      "Processing movies 1100 to 1200...\n",
      "Saved batch 1100–1200 in 17.1 sec. Total done: 1200\n",
      "Processing movies 1200 to 1300...\n",
      "Saved batch 1200–1300 in 17.3 sec. Total done: 1300\n",
      "Processing movies 1300 to 1400...\n",
      "Saved batch 1300–1400 in 17.5 sec. Total done: 1400\n",
      "Processing movies 1400 to 1500...\n",
      "Saved batch 1400–1500 in 17.2 sec. Total done: 1500\n",
      "Processing movies 1500 to 1600...\n",
      "Saved batch 1500–1600 in 17.5 sec. Total done: 1600\n",
      "Processing movies 1600 to 1700...\n",
      "Saved batch 1600–1700 in 17.4 sec. Total done: 1700\n",
      "Processing movies 1700 to 1800...\n",
      "Saved batch 1700–1800 in 17.6 sec. Total done: 1800\n",
      "Processing movies 1800 to 1900...\n",
      "Saved batch 1800–1900 in 16.0 sec. Total done: 1900\n",
      "Processing movies 1900 to 2000...\n",
      "Saved batch 1900–2000 in 17.3 sec. Total done: 2000\n",
      "Processing movies 2000 to 2100...\n",
      "Saved batch 2000–2100 in 17.1 sec. Total done: 2100\n",
      "Processing movies 2100 to 2200...\n",
      "Saved batch 2100–2200 in 16.7 sec. Total done: 2200\n",
      "Processing movies 2200 to 2300...\n",
      "Saved batch 2200–2300 in 17.2 sec. Total done: 2300\n",
      "Processing movies 2300 to 2400...\n",
      "Saved batch 2300–2400 in 17.0 sec. Total done: 2400\n",
      "Processing movies 2400 to 2500...\n",
      "Saved batch 2400–2500 in 16.6 sec. Total done: 2500\n",
      "Processing movies 2500 to 2600...\n",
      "Saved batch 2500–2600 in 16.6 sec. Total done: 2600\n",
      "Processing movies 2600 to 2700...\n",
      "Saved batch 2600–2700 in 15.9 sec. Total done: 2700\n",
      "Processing movies 2700 to 2800...\n",
      "Saved batch 2700–2800 in 16.5 sec. Total done: 2800\n",
      "Processing movies 2800 to 2900...\n",
      "Saved batch 2800–2900 in 17.1 sec. Total done: 2900\n",
      "Processing movies 2900 to 3000...\n",
      "Saved batch 2900–3000 in 17.0 sec. Total done: 3000\n",
      "Processing movies 3000 to 3100...\n",
      "Saved batch 3000–3100 in 18.0 sec. Total done: 3100\n",
      "Processing movies 3100 to 3200...\n",
      "Saved batch 3100–3200 in 16.1 sec. Total done: 3200\n",
      "Processing movies 3200 to 3300...\n",
      "Saved batch 3200–3300 in 17.3 sec. Total done: 3300\n",
      "Processing movies 3300 to 3400...\n",
      "Saved batch 3300–3400 in 16.1 sec. Total done: 3400\n",
      "Processing movies 3400 to 3500...\n",
      "Saved batch 3400–3500 in 16.7 sec. Total done: 3500\n",
      "Processing movies 3500 to 3600...\n",
      "Saved batch 3500–3600 in 16.4 sec. Total done: 3600\n",
      "Processing movies 3600 to 3700...\n",
      "Saved batch 3600–3700 in 16.3 sec. Total done: 3700\n",
      "Processing movies 3700 to 3800...\n",
      "Saved batch 3700–3800 in 16.6 sec. Total done: 3800\n",
      "Processing movies 3800 to 3900...\n",
      "Saved batch 3800–3900 in 16.4 sec. Total done: 3900\n",
      "Processing movies 3900 to 4000...\n",
      "Saved batch 3900–4000 in 16.9 sec. Total done: 4000\n",
      "Processing movies 4000 to 4100...\n",
      "Saved batch 4000–4100 in 17.2 sec. Total done: 4100\n",
      "Processing movies 4100 to 4200...\n",
      "Saved batch 4100–4200 in 17.2 sec. Total done: 4200\n",
      "Processing movies 4200 to 4300...\n",
      "Saved batch 4200–4300 in 16.4 sec. Total done: 4300\n",
      "Processing movies 4300 to 4400...\n",
      "Saved batch 4300–4400 in 16.1 sec. Total done: 4400\n",
      "Processing movies 4400 to 4500...\n",
      "Saved batch 4400–4500 in 16.2 sec. Total done: 4500\n",
      "Processing movies 4500 to 4600...\n",
      "Saved batch 4500–4600 in 17.3 sec. Total done: 4600\n",
      "Processing movies 4600 to 4700...\n",
      "Saved batch 4600–4700 in 17.0 sec. Total done: 4700\n",
      "Processing movies 4700 to 4800...\n",
      "Saved batch 4700–4800 in 16.6 sec. Total done: 4800\n",
      "Processing movies 4800 to 4900...\n",
      "Saved batch 4800–4900 in 16.7 sec. Total done: 4900\n",
      "Processing movies 4900 to 5000...\n",
      "Saved batch 4900–5000 in 17.2 sec. Total done: 5000\n",
      "Processing movies 5000 to 5100...\n",
      "Saved batch 5000–5100 in 17.3 sec. Total done: 5100\n",
      "Processing movies 5100 to 5200...\n",
      "Saved batch 5100–5200 in 16.9 sec. Total done: 5200\n",
      "Processing movies 5200 to 5300...\n",
      "Saved batch 5200–5300 in 17.3 sec. Total done: 5300\n",
      "Processing movies 5300 to 5400...\n",
      "Saved batch 5300–5400 in 17.6 sec. Total done: 5400\n",
      "Processing movies 5400 to 5500...\n",
      "Saved batch 5400–5500 in 17.0 sec. Total done: 5500\n",
      "Processing movies 5500 to 5600...\n",
      "Saved batch 5500–5600 in 17.6 sec. Total done: 5600\n",
      "Processing movies 5600 to 5700...\n",
      "Saved batch 5600–5700 in 16.4 sec. Total done: 5700\n",
      "Processing movies 5700 to 5800...\n",
      "Saved batch 5700–5800 in 16.6 sec. Total done: 5800\n",
      "Processing movies 5800 to 5900...\n",
      "Saved batch 5800–5900 in 16.8 sec. Total done: 5900\n",
      "Processing movies 5900 to 6000...\n",
      "Saved batch 5900–6000 in 17.1 sec. Total done: 6000\n",
      "Processing movies 6000 to 6100...\n",
      "Saved batch 6000–6100 in 17.1 sec. Total done: 6100\n",
      "Processing movies 6100 to 6200...\n",
      "Saved batch 6100–6200 in 17.3 sec. Total done: 6200\n",
      "Processing movies 6200 to 6300...\n",
      "Saved batch 6200–6300 in 17.5 sec. Total done: 6300\n",
      "Processing movies 6300 to 6400...\n",
      "Saved batch 6300–6400 in 17.4 sec. Total done: 6400\n",
      "Processing movies 6400 to 6500...\n",
      "Saved batch 6400–6500 in 16.7 sec. Total done: 6500\n",
      "Processing movies 6500 to 6600...\n",
      "Saved batch 6500–6600 in 15.7 sec. Total done: 6600\n",
      "Processing movies 6600 to 6700...\n",
      "Saved batch 6600–6700 in 15.7 sec. Total done: 6700\n",
      "Processing movies 6700 to 6800...\n",
      "Saved batch 6700–6800 in 15.7 sec. Total done: 6800\n",
      "Processing movies 6800 to 6900...\n",
      "Saved batch 6800–6900 in 15.9 sec. Total done: 6900\n",
      "Processing movies 6900 to 7000...\n",
      "Saved batch 6900–7000 in 15.7 sec. Total done: 7000\n",
      "Processing movies 7000 to 7100...\n",
      "Saved batch 7000–7100 in 15.8 sec. Total done: 7100\n",
      "Processing movies 7100 to 7200...\n",
      "Saved batch 7100–7200 in 15.8 sec. Total done: 7200\n",
      "Processing movies 7200 to 7300...\n",
      "Saved batch 7200–7300 in 15.7 sec. Total done: 7300\n",
      "Processing movies 7300 to 7400...\n",
      "Saved batch 7300–7400 in 15.7 sec. Total done: 7400\n",
      "Processing movies 7400 to 7500...\n",
      "Saved batch 7400–7500 in 15.7 sec. Total done: 7500\n",
      "Processing movies 7500 to 7600...\n",
      "Saved batch 7500–7600 in 15.8 sec. Total done: 7600\n",
      "Processing movies 7600 to 7700...\n",
      "Saved batch 7600–7700 in 15.7 sec. Total done: 7700\n",
      "Processing movies 7700 to 7800...\n",
      "Saved batch 7700–7800 in 16.0 sec. Total done: 7800\n",
      "Processing movies 7800 to 7900...\n",
      "Saved batch 7800–7900 in 17.0 sec. Total done: 7900\n",
      "Processing movies 7900 to 8000...\n",
      "Saved batch 7900–8000 in 17.5 sec. Total done: 8000\n",
      "Processing movies 8000 to 8100...\n",
      "Saved batch 8000–8100 in 16.7 sec. Total done: 8100\n",
      "Processing movies 8100 to 8200...\n",
      "Saved batch 8100–8200 in 16.6 sec. Total done: 8200\n",
      "Processing movies 8200 to 8300...\n",
      "Saved batch 8200–8300 in 16.2 sec. Total done: 8300\n",
      "Processing movies 8300 to 8400...\n",
      "Saved batch 8300–8400 in 17.5 sec. Total done: 8400\n",
      "Processing movies 8400 to 8500...\n",
      "Saved batch 8400–8500 in 17.5 sec. Total done: 8500\n",
      "Processing movies 8500 to 8600...\n",
      "Saved batch 8500–8600 in 16.4 sec. Total done: 8600\n",
      "Processing movies 8600 to 8700...\n",
      "Saved batch 8600–8700 in 16.2 sec. Total done: 8700\n",
      "Processing movies 8700 to 8800...\n",
      "Saved batch 8700–8800 in 16.4 sec. Total done: 8800\n",
      "Processing movies 8800 to 8900...\n",
      "Saved batch 8800–8900 in 17.1 sec. Total done: 8900\n",
      "Processing movies 8900 to 9000...\n",
      "Saved batch 8900–9000 in 17.2 sec. Total done: 9000\n",
      "Processing movies 9000 to 9100...\n",
      "Saved batch 9000–9100 in 17.2 sec. Total done: 9100\n",
      "Processing movies 9100 to 9200...\n",
      "Saved batch 9100–9200 in 17.2 sec. Total done: 9200\n",
      "Processing movies 9200 to 9300...\n",
      "Saved batch 9200–9300 in 17.0 sec. Total done: 9300\n",
      "Processing movies 9300 to 9400...\n",
      "Saved batch 9300–9400 in 18.0 sec. Total done: 9400\n",
      "Processing movies 9400 to 9500...\n",
      "Saved batch 9400–9500 in 18.3 sec. Total done: 9500\n",
      "Processing movies 9500 to 9600...\n",
      "Saved batch 9500–9600 in 16.2 sec. Total done: 9600\n",
      "Processing movies 9600 to 9700...\n",
      "Saved batch 9600–9700 in 16.1 sec. Total done: 9700\n",
      "Processing movies 9700 to 9800...\n",
      "Saved batch 9700–9800 in 16.3 sec. Total done: 9800\n",
      "Processing movies 9800 to 9900...\n",
      "Saved batch 9800–9900 in 16.9 sec. Total done: 9900\n",
      "Processing movies 9900 to 10000...\n",
      "Saved batch 9900–10000 in 17.5 sec. Total done: 10000\n",
      "Processing movies 10000 to 10100...\n",
      "Saved batch 10000–10100 in 15.7 sec. Total done: 10100\n",
      "Processing movies 10100 to 10200...\n",
      "Saved batch 10100–10200 in 15.7 sec. Total done: 10200\n",
      "Processing movies 10200 to 10300...\n",
      "Saved batch 10200–10300 in 15.8 sec. Total done: 10300\n",
      "Processing movies 10300 to 10400...\n",
      "Saved batch 10300–10400 in 15.7 sec. Total done: 10400\n",
      "Processing movies 10400 to 10500...\n",
      "Saved batch 10400–10500 in 15.8 sec. Total done: 10500\n",
      "Processing movies 10500 to 10600...\n",
      "Saved batch 10500–10600 in 16.1 sec. Total done: 10600\n",
      "Processing movies 10600 to 10700...\n",
      "Saved batch 10600–10700 in 15.7 sec. Total done: 10700\n",
      "Processing movies 10700 to 10800...\n",
      "Saved batch 10700–10800 in 15.7 sec. Total done: 10800\n",
      "Processing movies 10800 to 10900...\n",
      "Saved batch 10800–10900 in 15.9 sec. Total done: 10900\n",
      "Processing movies 10900 to 11000...\n",
      "Saved batch 10900–11000 in 15.7 sec. Total done: 11000\n",
      "Processing movies 11000 to 11100...\n",
      "Saved batch 11000–11100 in 15.7 sec. Total done: 11100\n",
      "Processing movies 11100 to 11200...\n",
      "Saved batch 11100–11200 in 15.7 sec. Total done: 11200\n",
      "Processing movies 11200 to 11300...\n",
      "Saved batch 11200–11300 in 15.6 sec. Total done: 11300\n",
      "Processing movies 11300 to 11400...\n",
      "Saved batch 11300–11400 in 15.6 sec. Total done: 11400\n",
      "Processing movies 11400 to 11500...\n",
      "Saved batch 11400–11500 in 15.7 sec. Total done: 11500\n",
      "Processing movies 11500 to 11600...\n",
      "Saved batch 11500–11600 in 15.6 sec. Total done: 11600\n",
      "Processing movies 11600 to 11700...\n",
      "Saved batch 11600–11700 in 15.7 sec. Total done: 11700\n",
      "Processing movies 11700 to 11800...\n",
      "Saved batch 11700–11800 in 15.8 sec. Total done: 11800\n",
      "Processing movies 11800 to 11900...\n",
      "Saved batch 11800–11900 in 15.6 sec. Total done: 11900\n",
      "Processing movies 11900 to 12000...\n",
      "Saved batch 11900–12000 in 15.7 sec. Total done: 12000\n",
      "Processing movies 12000 to 12100...\n",
      "Saved batch 12000–12100 in 15.7 sec. Total done: 12100\n",
      "Processing movies 12100 to 12200...\n",
      "Saved batch 12100–12200 in 15.7 sec. Total done: 12200\n",
      "Processing movies 12200 to 12300...\n",
      "Saved batch 12200–12300 in 15.7 sec. Total done: 12300\n",
      "Processing movies 12300 to 12400...\n",
      "Saved batch 12300–12400 in 16.6 sec. Total done: 12400\n",
      "Processing movies 12400 to 12500...\n",
      "Saved batch 12400–12500 in 15.8 sec. Total done: 12500\n",
      "Processing movies 12500 to 12600...\n",
      "Saved batch 12500–12600 in 15.9 sec. Total done: 12600\n",
      "Processing movies 12600 to 12700...\n",
      "Saved batch 12600–12700 in 15.8 sec. Total done: 12700\n",
      "Processing movies 12700 to 12800...\n",
      "Saved batch 12700–12800 in 15.8 sec. Total done: 12800\n",
      "Processing movies 12800 to 12900...\n",
      "Saved batch 12800–12900 in 16.0 sec. Total done: 12900\n",
      "Processing movies 12900 to 13000...\n",
      "Saved batch 12900–13000 in 16.8 sec. Total done: 13000\n",
      "Processing movies 13000 to 13100...\n",
      "Saved batch 13000–13100 in 16.4 sec. Total done: 13100\n",
      "Processing movies 13100 to 13200...\n",
      "Saved batch 13100–13200 in 17.8 sec. Total done: 13200\n",
      "Processing movies 13200 to 13300...\n",
      "Saved batch 13200–13300 in 16.0 sec. Total done: 13300\n",
      "Processing movies 13300 to 13400...\n",
      "Saved batch 13300–13400 in 16.6 sec. Total done: 13400\n",
      "Processing movies 13400 to 13500...\n",
      "Saved batch 13400–13500 in 18.7 sec. Total done: 13500\n",
      "Processing movies 13500 to 13600...\n",
      "Saved batch 13500–13600 in 16.2 sec. Total done: 13600\n",
      "Processing movies 13600 to 13700...\n",
      "Saved batch 13600–13700 in 28.0 sec. Total done: 13700\n",
      "Processing movies 13700 to 13800...\n",
      "Saved batch 13700–13800 in 21.3 sec. Total done: 13800\n",
      "Processing movies 13800 to 13900...\n",
      "Saved batch 13800–13900 in 16.5 sec. Total done: 13900\n",
      "Processing movies 13900 to 14000...\n",
      "Saved batch 13900–14000 in 17.8 sec. Total done: 14000\n",
      "Processing movies 14000 to 14100...\n",
      "Saved batch 14000–14100 in 17.7 sec. Total done: 14100\n",
      "Processing movies 14100 to 14200...\n",
      "Saved batch 14100–14200 in 18.3 sec. Total done: 14200\n",
      "Processing movies 14200 to 14300...\n",
      "Saved batch 14200–14300 in 16.8 sec. Total done: 14300\n",
      "Processing movies 14300 to 14400...\n",
      "Saved batch 14300–14400 in 17.6 sec. Total done: 14400\n",
      "Processing movies 14400 to 14500...\n",
      "Saved batch 14400–14500 in 17.2 sec. Total done: 14500\n",
      "Processing movies 14500 to 14600...\n",
      "Saved batch 14500–14600 in 16.8 sec. Total done: 14600\n",
      "Processing movies 14600 to 14700...\n",
      "Saved batch 14600–14700 in 18.5 sec. Total done: 14700\n",
      "Processing movies 14700 to 14800...\n",
      "Saved batch 14700–14800 in 16.6 sec. Total done: 14800\n",
      "Processing movies 14800 to 14900...\n",
      "Saved batch 14800–14900 in 16.5 sec. Total done: 14900\n",
      "Processing movies 14900 to 15000...\n",
      "Saved batch 14900–15000 in 16.6 sec. Total done: 15000\n",
      "Processing movies 15000 to 15100...\n",
      "Saved batch 15000–15100 in 17.5 sec. Total done: 15100\n",
      "Processing movies 15100 to 15200...\n",
      "Saved batch 15100–15200 in 16.4 sec. Total done: 15200\n",
      "Processing movies 15200 to 15300...\n",
      "Saved batch 15200–15300 in 17.8 sec. Total done: 15300\n",
      "Processing movies 15300 to 15400...\n",
      "Saved batch 15300–15400 in 17.6 sec. Total done: 15400\n",
      "Processing movies 15400 to 15500...\n",
      "Saved batch 15400–15500 in 18.0 sec. Total done: 15500\n",
      "Processing movies 15500 to 15600...\n",
      "Saved batch 15500–15600 in 18.5 sec. Total done: 15600\n",
      "Processing movies 15600 to 15700...\n",
      "Saved batch 15600–15700 in 16.5 sec. Total done: 15700\n",
      "Processing movies 15700 to 15800...\n",
      "Saved batch 15700–15800 in 17.1 sec. Total done: 15800\n",
      "Processing movies 15800 to 15900...\n",
      "Saved batch 15800–15900 in 18.1 sec. Total done: 15900\n",
      "Processing movies 15900 to 16000...\n",
      "Saved batch 15900–16000 in 16.5 sec. Total done: 16000\n",
      "Processing movies 16000 to 16100...\n",
      "Saved batch 16000–16100 in 16.4 sec. Total done: 16100\n",
      "Processing movies 16100 to 16200...\n",
      "Saved batch 16100–16200 in 17.6 sec. Total done: 16200\n",
      "Processing movies 16200 to 16300...\n",
      "Saved batch 16200–16300 in 16.9 sec. Total done: 16300\n",
      "Processing movies 16300 to 16400...\n",
      "Saved batch 16300–16400 in 17.9 sec. Total done: 16400\n",
      "Processing movies 16400 to 16500...\n",
      "Saved batch 16400–16500 in 16.4 sec. Total done: 16500\n",
      "Processing movies 16500 to 16600...\n",
      "Saved batch 16500–16600 in 18.2 sec. Total done: 16600\n",
      "Processing movies 16600 to 16700...\n",
      "Saved batch 16600–16700 in 16.4 sec. Total done: 16700\n",
      "Processing movies 16700 to 16800...\n",
      "Saved batch 16700–16800 in 17.0 sec. Total done: 16800\n",
      "Processing movies 16800 to 16900...\n",
      "Saved batch 16800–16900 in 16.8 sec. Total done: 16900\n",
      "Processing movies 16900 to 17000...\n",
      "Saved batch 16900–17000 in 15.4 sec. Total done: 17000\n",
      "Processing movies 17000 to 17100...\n",
      "Saved batch 17000–17100 in 16.6 sec. Total done: 17100\n",
      "Processing movies 17100 to 17200...\n",
      "Saved batch 17100–17200 in 17.7 sec. Total done: 17200\n",
      "Processing movies 17200 to 17300...\n",
      "Saved batch 17200–17300 in 16.0 sec. Total done: 17300\n",
      "Processing movies 17300 to 17400...\n",
      "Saved batch 17300–17400 in 15.4 sec. Total done: 17400\n",
      "Processing movies 17400 to 17500...\n",
      "Saved batch 17400–17500 in 15.6 sec. Total done: 17500\n",
      "Processing movies 17500 to 17600...\n",
      "Saved batch 17500–17600 in 15.4 sec. Total done: 17600\n",
      "Processing movies 17600 to 17700...\n",
      "Saved batch 17600–17700 in 15.5 sec. Total done: 17700\n",
      "Processing movies 17700 to 17800...\n",
      "Saved batch 17700–17800 in 15.7 sec. Total done: 17800\n",
      "Processing movies 17800 to 17900...\n",
      "Saved batch 17800–17900 in 16.1 sec. Total done: 17900\n",
      "Processing movies 17900 to 18000...\n",
      "Saved batch 17900–18000 in 15.7 sec. Total done: 18000\n",
      "Processing movies 18000 to 18100...\n",
      "Saved batch 18000–18100 in 16.7 sec. Total done: 18100\n",
      "Processing movies 18100 to 18200...\n",
      "Saved batch 18100–18200 in 17.0 sec. Total done: 18200\n",
      "Processing movies 18200 to 18300...\n",
      "Saved batch 18200–18300 in 17.2 sec. Total done: 18300\n",
      "Processing movies 18300 to 18400...\n",
      "Saved batch 18300–18400 in 17.2 sec. Total done: 18400\n",
      "Processing movies 18400 to 18500...\n",
      "Saved batch 18400–18500 in 16.7 sec. Total done: 18500\n",
      "Processing movies 18500 to 18600...\n",
      "Saved batch 18500–18600 in 16.2 sec. Total done: 18600\n",
      "Processing movies 18600 to 18700...\n",
      "Saved batch 18600–18700 in 17.0 sec. Total done: 18700\n",
      "Processing movies 18700 to 18800...\n",
      "Saved batch 18700–18800 in 17.8 sec. Total done: 18800\n",
      "Processing movies 18800 to 18900...\n",
      "Saved batch 18800–18900 in 16.5 sec. Total done: 18900\n",
      "Processing movies 18900 to 19000...\n",
      "Saved batch 18900–19000 in 17.7 sec. Total done: 19000\n",
      "Processing movies 19000 to 19100...\n",
      "Saved batch 19000–19100 in 16.2 sec. Total done: 19100\n",
      "Processing movies 19100 to 19200...\n",
      "Saved batch 19100–19200 in 17.3 sec. Total done: 19200\n",
      "Processing movies 19200 to 19300...\n",
      "Saved batch 19200–19300 in 16.1 sec. Total done: 19300\n",
      "Processing movies 19300 to 19400...\n",
      "Saved batch 19300–19400 in 17.1 sec. Total done: 19400\n",
      "Processing movies 19400 to 19500...\n",
      "Saved batch 19400–19500 in 18.3 sec. Total done: 19500\n",
      "Processing movies 19500 to 19600...\n",
      "Saved batch 19500–19600 in 16.5 sec. Total done: 19600\n",
      "Processing movies 19600 to 19700...\n",
      "Saved batch 19600–19700 in 18.5 sec. Total done: 19700\n",
      "Processing movies 19700 to 19800...\n",
      "Saved batch 19700–19800 in 17.8 sec. Total done: 19800\n",
      "Processing movies 19800 to 19900...\n",
      "Saved batch 19800–19900 in 16.3 sec. Total done: 19900\n",
      "Processing movies 19900 to 20000...\n",
      "Saved batch 19900–20000 in 16.9 sec. Total done: 20000\n",
      "Processing movies 20000 to 20100...\n",
      "Saved batch 20000–20100 in 18.6 sec. Total done: 20100\n",
      "Processing movies 20100 to 20200...\n",
      "Saved batch 20100–20200 in 16.7 sec. Total done: 20200\n",
      "Processing movies 20200 to 20300...\n",
      "Saved batch 20200–20300 in 16.4 sec. Total done: 20300\n",
      "Processing movies 20300 to 20400...\n",
      "Saved batch 20300–20400 in 16.5 sec. Total done: 20400\n",
      "Processing movies 20400 to 20500...\n",
      "Saved batch 20400–20500 in 17.9 sec. Total done: 20500\n",
      "Processing movies 20500 to 20600...\n",
      "Saved batch 20500–20600 in 17.8 sec. Total done: 20600\n",
      "Processing movies 20600 to 20700...\n",
      "Saved batch 20600–20700 in 16.1 sec. Total done: 20700\n",
      "Processing movies 20700 to 20800...\n",
      "Saved batch 20700–20800 in 16.4 sec. Total done: 20800\n",
      "Processing movies 20800 to 20900...\n",
      "Saved batch 20800–20900 in 16.4 sec. Total done: 20900\n",
      "Processing movies 20900 to 21000...\n",
      "Saved batch 20900–21000 in 16.8 sec. Total done: 21000\n",
      "Processing movies 21000 to 21100...\n",
      "Saved batch 21000–21100 in 15.7 sec. Total done: 21100\n",
      "Processing movies 21100 to 21200...\n",
      "Saved batch 21100–21200 in 16.3 sec. Total done: 21200\n",
      "Processing movies 21200 to 21300...\n",
      "Saved batch 21200–21300 in 16.5 sec. Total done: 21300\n",
      "Processing movies 21300 to 21400...\n",
      "Saved batch 21300–21400 in 16.7 sec. Total done: 21400\n",
      "Processing movies 21400 to 21500...\n",
      "Saved batch 21400–21500 in 16.5 sec. Total done: 21500\n",
      "Processing movies 21500 to 21600...\n",
      "Saved batch 21500–21600 in 16.4 sec. Total done: 21600\n",
      "Processing movies 21600 to 21700...\n",
      "Saved batch 21600–21700 in 16.9 sec. Total done: 21700\n",
      "Processing movies 21700 to 21800...\n",
      "Saved batch 21700–21800 in 16.3 sec. Total done: 21800\n",
      "Processing movies 21800 to 21900...\n",
      "Saved batch 21800–21900 in 16.8 sec. Total done: 21900\n",
      "Processing movies 21900 to 22000...\n",
      "Saved batch 21900–22000 in 16.6 sec. Total done: 22000\n",
      "Processing movies 22000 to 22100...\n",
      "Saved batch 22000–22100 in 17.0 sec. Total done: 22100\n",
      "Processing movies 22100 to 22200...\n",
      "Saved batch 22100–22200 in 18.6 sec. Total done: 22200\n",
      "Processing movies 22200 to 22300...\n",
      "Saved batch 22200–22300 in 15.9 sec. Total done: 22300\n",
      "Processing movies 22300 to 22400...\n",
      "Saved batch 22300–22400 in 15.6 sec. Total done: 22400\n",
      "Processing movies 22400 to 22500...\n",
      "Saved batch 22400–22500 in 15.6 sec. Total done: 22500\n",
      "Processing movies 22500 to 22600...\n",
      "Saved batch 22500–22600 in 15.7 sec. Total done: 22600\n",
      "Processing movies 22600 to 22700...\n",
      "Saved batch 22600–22700 in 15.5 sec. Total done: 22700\n",
      "Processing movies 22700 to 22800...\n",
      "Saved batch 22700–22800 in 15.5 sec. Total done: 22800\n",
      "Processing movies 22800 to 22900...\n",
      "Saved batch 22800–22900 in 15.6 sec. Total done: 22900\n",
      "Processing movies 22900 to 23000...\n",
      "Saved batch 22900–23000 in 15.6 sec. Total done: 23000\n",
      "Processing movies 23000 to 23100...\n",
      "Saved batch 23000–23100 in 15.6 sec. Total done: 23100\n",
      "Processing movies 23100 to 23200...\n",
      "Saved batch 23100–23200 in 15.7 sec. Total done: 23200\n",
      "Processing movies 23200 to 23300...\n",
      "Saved batch 23200–23300 in 15.7 sec. Total done: 23300\n",
      "Processing movies 23300 to 23400...\n",
      "Saved batch 23300–23400 in 15.6 sec. Total done: 23400\n",
      "Processing movies 23400 to 23500...\n",
      "Saved batch 23400–23500 in 15.6 sec. Total done: 23500\n",
      "Processing movies 23500 to 23600...\n",
      "Saved batch 23500–23600 in 15.6 sec. Total done: 23600\n",
      "Processing movies 23600 to 23700...\n",
      "Saved batch 23600–23700 in 15.5 sec. Total done: 23700\n",
      "Processing movies 23700 to 23800...\n",
      "Saved batch 23700–23800 in 15.7 sec. Total done: 23800\n",
      "Processing movies 23800 to 23900...\n",
      "Saved batch 23800–23900 in 16.0 sec. Total done: 23900\n",
      "Processing movies 23900 to 24000...\n",
      "Saved batch 23900–24000 in 18.3 sec. Total done: 24000\n",
      "Processing movies 24000 to 24100...\n",
      "Saved batch 24000–24100 in 19.4 sec. Total done: 24100\n",
      "Processing movies 24100 to 24200...\n",
      "Saved batch 24100–24200 in 21.5 sec. Total done: 24200\n",
      "Processing movies 24200 to 24300...\n",
      "Saved batch 24200–24300 in 24.7 sec. Total done: 24300\n",
      "Processing movies 24300 to 24400...\n",
      "Saved batch 24300–24400 in 21.1 sec. Total done: 24400\n",
      "Processing movies 24400 to 24500...\n",
      "Saved batch 24400–24500 in 20.1 sec. Total done: 24500\n",
      "Processing movies 24500 to 24600...\n",
      "Saved batch 24500–24600 in 20.1 sec. Total done: 24600\n",
      "Processing movies 24600 to 24700...\n",
      "Saved batch 24600–24700 in 20.1 sec. Total done: 24700\n",
      "Processing movies 24700 to 24800...\n",
      "Saved batch 24700–24800 in 20.0 sec. Total done: 24800\n",
      "Processing movies 24800 to 24900...\n",
      "Saved batch 24800–24900 in 20.8 sec. Total done: 24900\n",
      "Processing movies 24900 to 25000...\n",
      "Saved batch 24900–25000 in 20.2 sec. Total done: 25000\n",
      "Processing movies 25000 to 25100...\n",
      "Saved batch 25000–25100 in 19.8 sec. Total done: 25100\n",
      "Processing movies 25100 to 25200...\n",
      "Saved batch 25100–25200 in 20.1 sec. Total done: 25200\n",
      "Processing movies 25200 to 25300...\n",
      "Saved batch 25200–25300 in 19.9 sec. Total done: 25300\n",
      "Processing movies 25300 to 25400...\n",
      "Saved batch 25300–25400 in 21.1 sec. Total done: 25400\n",
      "Processing movies 25400 to 25500...\n",
      "Saved batch 25400–25500 in 21.0 sec. Total done: 25500\n",
      "Processing movies 25500 to 25600...\n",
      "Saved batch 25500–25600 in 24.3 sec. Total done: 25600\n",
      "Processing movies 25600 to 25700...\n",
      "Saved batch 25600–25700 in 20.7 sec. Total done: 25700\n",
      "Processing movies 25700 to 25800...\n",
      "Saved batch 25700–25800 in 20.5 sec. Total done: 25800\n",
      "Processing movies 25800 to 25900...\n",
      "Saved batch 25800–25900 in 19.9 sec. Total done: 25900\n",
      "Processing movies 25900 to 26000...\n",
      "Saved batch 25900–26000 in 20.6 sec. Total done: 26000\n",
      "Processing movies 26000 to 26100...\n",
      "Saved batch 26000–26100 in 21.0 sec. Total done: 26100\n",
      "Processing movies 26100 to 26200...\n",
      "Saved batch 26100–26200 in 20.0 sec. Total done: 26200\n",
      "Processing movies 26200 to 26300...\n",
      "Saved batch 26200–26300 in 19.7 sec. Total done: 26300\n",
      "Processing movies 26300 to 26400...\n",
      "Saved batch 26300–26400 in 19.7 sec. Total done: 26400\n",
      "Processing movies 26400 to 26500...\n",
      "Saved batch 26400–26500 in 21.7 sec. Total done: 26500\n",
      "Processing movies 26500 to 26600...\n",
      "Saved batch 26500–26600 in 19.8 sec. Total done: 26600\n",
      "Processing movies 26600 to 26700...\n",
      "Saved batch 26600–26700 in 19.5 sec. Total done: 26700\n",
      "Processing movies 26700 to 26800...\n",
      "Saved batch 26700–26800 in 19.9 sec. Total done: 26800\n",
      "Processing movies 26800 to 26900...\n",
      "Saved batch 26800–26900 in 19.8 sec. Total done: 26900\n",
      "Processing movies 26900 to 27000...\n",
      "Saved batch 26900–27000 in 19.7 sec. Total done: 27000\n",
      "Processing movies 27000 to 27100...\n",
      "Saved batch 27000–27100 in 19.9 sec. Total done: 27100\n",
      "Processing movies 27100 to 27200...\n",
      "Saved batch 27100–27200 in 19.7 sec. Total done: 27200\n",
      "Processing movies 27200 to 27300...\n",
      "Saved batch 27200–27300 in 20.1 sec. Total done: 27300\n",
      "Processing movies 27300 to 27400...\n",
      "Saved batch 27300–27400 in 19.9 sec. Total done: 27400\n",
      "Processing movies 27400 to 27500...\n",
      "Saved batch 27400–27500 in 20.0 sec. Total done: 27500\n",
      "Processing movies 27500 to 27600...\n",
      "Saved batch 27500–27600 in 20.8 sec. Total done: 27600\n",
      "Processing movies 27600 to 27700...\n",
      "Saved batch 27600–27700 in 21.2 sec. Total done: 27700\n",
      "Processing movies 27700 to 27800...\n",
      "Saved batch 27700–27800 in 20.8 sec. Total done: 27800\n",
      "Processing movies 27800 to 27900...\n",
      "Saved batch 27800–27900 in 20.8 sec. Total done: 27900\n",
      "Processing movies 27900 to 28000...\n",
      "Saved batch 27900–28000 in 20.7 sec. Total done: 28000\n",
      "Processing movies 28000 to 28100...\n",
      "Saved batch 28000–28100 in 20.5 sec. Total done: 28100\n",
      "Processing movies 28100 to 28200...\n",
      "Saved batch 28100–28200 in 21.0 sec. Total done: 28200\n",
      "Processing movies 28200 to 28300...\n",
      "Saved batch 28200–28300 in 21.4 sec. Total done: 28300\n",
      "Processing movies 28300 to 28400...\n",
      "Saved batch 28300–28400 in 22.4 sec. Total done: 28400\n",
      "Processing movies 28400 to 28500...\n",
      "Saved batch 28400–28500 in 21.2 sec. Total done: 28500\n",
      "Processing movies 28500 to 28600...\n",
      "Saved batch 28500–28600 in 20.8 sec. Total done: 28600\n",
      "Processing movies 28600 to 28700...\n",
      "Saved batch 28600–28700 in 21.1 sec. Total done: 28700\n",
      "Processing movies 28700 to 28800...\n",
      "Saved batch 28700–28800 in 17.3 sec. Total done: 28800\n",
      "Processing movies 28800 to 28900...\n",
      "Saved batch 28800–28900 in 20.5 sec. Total done: 28900\n",
      "Processing movies 28900 to 29000...\n",
      "Saved batch 28900–29000 in 20.5 sec. Total done: 29000\n",
      "Processing movies 29000 to 29100...\n",
      "Saved batch 29000–29100 in 17.9 sec. Total done: 29100\n",
      "Processing movies 29100 to 29200...\n",
      "Saved batch 29100–29200 in 15.8 sec. Total done: 29200\n",
      "Processing movies 29200 to 29300...\n",
      "Saved batch 29200–29300 in 19.2 sec. Total done: 29300\n",
      "Processing movies 29300 to 29400...\n",
      "Saved batch 29300–29400 in 21.3 sec. Total done: 29400\n",
      "Processing movies 29400 to 29500...\n",
      "Saved batch 29400–29500 in 21.7 sec. Total done: 29500\n",
      "Processing movies 29500 to 29600...\n",
      "Saved batch 29500–29600 in 21.1 sec. Total done: 29600\n",
      "Processing movies 29600 to 29700...\n",
      "Saved batch 29600–29700 in 20.0 sec. Total done: 29700\n",
      "Processing movies 29700 to 29800...\n",
      "Saved batch 29700–29800 in 22.3 sec. Total done: 29800\n",
      "Processing movies 29800 to 29900...\n",
      "Saved batch 29800–29900 in 20.5 sec. Total done: 29900\n",
      "Processing movies 29900 to 30000...\n",
      "Saved batch 29900–30000 in 20.9 sec. Total done: 30000\n",
      "Processing movies 30000 to 30100...\n",
      "Saved batch 30000–30100 in 21.3 sec. Total done: 30100\n",
      "Processing movies 30100 to 30200...\n",
      "Saved batch 30100–30200 in 20.2 sec. Total done: 30200\n",
      "Processing movies 30200 to 30300...\n",
      "Saved batch 30200–30300 in 19.9 sec. Total done: 30300\n",
      "Processing movies 30300 to 30400...\n",
      "Saved batch 30300–30400 in 20.4 sec. Total done: 30400\n",
      "Processing movies 30400 to 30500...\n",
      "Saved batch 30400–30500 in 21.1 sec. Total done: 30500\n",
      "Processing movies 30500 to 30600...\n",
      "Saved batch 30500–30600 in 20.5 sec. Total done: 30600\n",
      "Processing movies 30600 to 30700...\n",
      "Saved batch 30600–30700 in 22.6 sec. Total done: 30700\n",
      "Processing movies 30700 to 30800...\n",
      "Saved batch 30700–30800 in 22.0 sec. Total done: 30800\n",
      "Processing movies 30800 to 30900...\n",
      "Saved batch 30800–30900 in 19.5 sec. Total done: 30900\n",
      "Processing movies 30900 to 31000...\n",
      "Saved batch 30900–31000 in 21.0 sec. Total done: 31000\n",
      "Processing movies 31000 to 31100...\n",
      "Saved batch 31000–31100 in 16.8 sec. Total done: 31100\n",
      "Processing movies 31100 to 31200...\n",
      "Saved batch 31100–31200 in 16.3 sec. Total done: 31200\n",
      "Processing movies 31200 to 31300...\n",
      "Saved batch 31200–31300 in 16.3 sec. Total done: 31300\n",
      "Processing movies 31300 to 31400...\n",
      "Saved batch 31300–31400 in 16.3 sec. Total done: 31400\n",
      "Processing movies 31400 to 31500...\n",
      "Saved batch 31400–31500 in 16.7 sec. Total done: 31500\n",
      "Processing movies 31500 to 31600...\n",
      "Saved batch 31500–31600 in 17.0 sec. Total done: 31600\n",
      "Processing movies 31600 to 31700...\n",
      "Saved batch 31600–31700 in 17.1 sec. Total done: 31700\n",
      "Processing movies 31700 to 31800...\n",
      "Saved batch 31700–31800 in 17.1 sec. Total done: 31800\n",
      "Processing movies 31800 to 31900...\n",
      "Saved batch 31800–31900 in 16.8 sec. Total done: 31900\n",
      "Processing movies 31900 to 32000...\n",
      "Saved batch 31900–32000 in 16.7 sec. Total done: 32000\n",
      "Processing movies 32000 to 32100...\n",
      "Saved batch 32000–32100 in 16.7 sec. Total done: 32100\n",
      "Processing movies 32100 to 32200...\n",
      "Saved batch 32100–32200 in 16.7 sec. Total done: 32200\n",
      "Processing movies 32200 to 32300...\n",
      "Saved batch 32200–32300 in 16.7 sec. Total done: 32300\n",
      "Processing movies 32300 to 32400...\n",
      "Saved batch 32300–32400 in 16.7 sec. Total done: 32400\n",
      "Processing movies 32400 to 32500...\n",
      "Saved batch 32400–32500 in 16.8 sec. Total done: 32500\n",
      "Processing movies 32500 to 32600...\n",
      "Saved batch 32500–32600 in 17.1 sec. Total done: 32600\n",
      "Processing movies 32600 to 32700...\n",
      "Saved batch 32600–32700 in 16.7 sec. Total done: 32700\n",
      "Processing movies 32700 to 32800...\n",
      "Saved batch 32700–32800 in 16.9 sec. Total done: 32800\n",
      "Processing movies 32800 to 32900...\n",
      "Saved batch 32800–32900 in 16.7 sec. Total done: 32900\n",
      "Processing movies 32900 to 33000...\n",
      "Saved batch 32900–33000 in 16.8 sec. Total done: 33000\n",
      "Processing movies 33000 to 33100...\n",
      "Saved batch 33000–33100 in 17.1 sec. Total done: 33100\n",
      "Processing movies 33100 to 33200...\n",
      "Saved batch 33100–33200 in 16.7 sec. Total done: 33200\n",
      "Processing movies 33200 to 33300...\n",
      "Saved batch 33200–33300 in 16.7 sec. Total done: 33300\n",
      "Processing movies 33300 to 33400...\n",
      "Saved batch 33300–33400 in 16.7 sec. Total done: 33400\n",
      "Processing movies 33400 to 33500...\n",
      "Saved batch 33400–33500 in 16.8 sec. Total done: 33500\n",
      "Processing movies 33500 to 33600...\n",
      "Saved batch 33500–33600 in 17.0 sec. Total done: 33600\n",
      "Processing movies 33600 to 33700...\n",
      "Saved batch 33600–33700 in 16.9 sec. Total done: 33700\n",
      "Processing movies 33700 to 33800...\n",
      "Saved batch 33700–33800 in 17.2 sec. Total done: 33800\n",
      "Processing movies 33800 to 33900...\n",
      "Saved batch 33800–33900 in 16.9 sec. Total done: 33900\n",
      "Processing movies 33900 to 34000...\n",
      "Saved batch 33900–34000 in 16.8 sec. Total done: 34000\n",
      "Processing movies 34000 to 34100...\n",
      "Saved batch 34000–34100 in 18.7 sec. Total done: 34100\n",
      "Processing movies 34100 to 34200...\n",
      "Saved batch 34100–34200 in 19.9 sec. Total done: 34200\n",
      "Processing movies 34200 to 34300...\n",
      "Saved batch 34200–34300 in 18.9 sec. Total done: 34300\n",
      "Processing movies 34300 to 34400...\n",
      "Saved batch 34300–34400 in 19.4 sec. Total done: 34400\n",
      "Processing movies 34400 to 34500...\n",
      "Saved batch 34400–34500 in 19.3 sec. Total done: 34500\n",
      "Processing movies 34500 to 34600...\n",
      "Saved batch 34500–34600 in 19.1 sec. Total done: 34600\n",
      "Processing movies 34600 to 34700...\n",
      "Saved batch 34600–34700 in 20.3 sec. Total done: 34700\n",
      "Processing movies 34700 to 34800...\n",
      "Saved batch 34700–34800 in 21.3 sec. Total done: 34800\n",
      "Processing movies 34800 to 34900...\n",
      "Saved batch 34800–34900 in 21.7 sec. Total done: 34900\n",
      "Processing movies 34900 to 35000...\n",
      "Saved batch 34900–35000 in 18.9 sec. Total done: 35000\n",
      "Processing movies 35000 to 35100...\n",
      "Saved batch 35000–35100 in 21.4 sec. Total done: 35100\n",
      "Processing movies 35100 to 35200...\n",
      "Saved batch 35100–35200 in 20.3 sec. Total done: 35200\n",
      "Processing movies 35200 to 35300...\n",
      "Saved batch 35200–35300 in 20.6 sec. Total done: 35300\n",
      "Processing movies 35300 to 35400...\n",
      "Saved batch 35300–35400 in 20.4 sec. Total done: 35400\n",
      "Processing movies 35400 to 35500...\n",
      "Saved batch 35400–35500 in 21.1 sec. Total done: 35500\n",
      "Processing movies 35500 to 35600...\n",
      "Saved batch 35500–35600 in 22.4 sec. Total done: 35600\n",
      "Processing movies 35600 to 35700...\n",
      "Saved batch 35600–35700 in 19.2 sec. Total done: 35700\n",
      "Processing movies 35700 to 35800...\n",
      "Saved batch 35700–35800 in 20.7 sec. Total done: 35800\n",
      "Processing movies 35800 to 35900...\n",
      "Saved batch 35800–35900 in 20.9 sec. Total done: 35900\n",
      "Processing movies 35900 to 36000...\n",
      "Saved batch 35900–36000 in 20.8 sec. Total done: 36000\n",
      "Processing movies 36000 to 36100...\n",
      "Saved batch 36000–36100 in 20.6 sec. Total done: 36100\n",
      "Processing movies 36100 to 36200...\n",
      "Saved batch 36100–36200 in 20.5 sec. Total done: 36200\n",
      "Processing movies 36200 to 36300...\n",
      "Saved batch 36200–36300 in 20.9 sec. Total done: 36300\n",
      "Processing movies 36300 to 36400...\n",
      "Saved batch 36300–36400 in 21.1 sec. Total done: 36400\n",
      "Processing movies 36400 to 36500...\n",
      "Saved batch 36400–36500 in 21.3 sec. Total done: 36500\n",
      "Processing movies 36500 to 36600...\n",
      "Saved batch 36500–36600 in 21.3 sec. Total done: 36600\n",
      "Processing movies 36600 to 36700...\n",
      "Saved batch 36600–36700 in 20.8 sec. Total done: 36700\n",
      "Processing movies 36700 to 36800...\n",
      "Saved batch 36700–36800 in 21.3 sec. Total done: 36800\n",
      "Processing movies 36800 to 36900...\n",
      "Saved batch 36800–36900 in 20.4 sec. Total done: 36900\n",
      "Processing movies 36900 to 37000...\n",
      "Saved batch 36900–37000 in 20.3 sec. Total done: 37000\n",
      "Processing movies 37000 to 37100...\n",
      "Saved batch 37000–37100 in 20.0 sec. Total done: 37100\n",
      "Processing movies 37100 to 37200...\n",
      "Saved batch 37100–37200 in 21.2 sec. Total done: 37200\n",
      "Processing movies 37200 to 37300...\n",
      "Saved batch 37200–37300 in 22.1 sec. Total done: 37300\n",
      "Processing movies 37300 to 37400...\n",
      "Saved batch 37300–37400 in 21.2 sec. Total done: 37400\n",
      "Processing movies 37400 to 37500...\n",
      "Saved batch 37400–37500 in 22.1 sec. Total done: 37500\n",
      "Processing movies 37500 to 37600...\n",
      "Saved batch 37500–37600 in 21.1 sec. Total done: 37600\n",
      "Processing movies 37600 to 37700...\n",
      "Saved batch 37600–37700 in 21.0 sec. Total done: 37700\n",
      "Processing movies 37700 to 37800...\n",
      "Saved batch 37700–37800 in 21.3 sec. Total done: 37800\n",
      "Processing movies 37800 to 37900...\n",
      "Saved batch 37800–37900 in 21.3 sec. Total done: 37900\n",
      "Processing movies 37900 to 38000...\n",
      "Saved batch 37900–38000 in 21.9 sec. Total done: 38000\n",
      "Processing movies 38000 to 38100...\n",
      "Saved batch 38000–38100 in 20.9 sec. Total done: 38100\n",
      "Processing movies 38100 to 38200...\n",
      "Saved batch 38100–38200 in 21.9 sec. Total done: 38200\n",
      "Processing movies 38200 to 38300...\n",
      "Saved batch 38200–38300 in 22.6 sec. Total done: 38300\n",
      "Processing movies 38300 to 38400...\n",
      "Saved batch 38300–38400 in 21.3 sec. Total done: 38400\n",
      "Processing movies 38400 to 38500...\n",
      "Saved batch 38400–38500 in 21.7 sec. Total done: 38500\n",
      "Processing movies 38500 to 38600...\n",
      "Saved batch 38500–38600 in 21.4 sec. Total done: 38600\n",
      "Processing movies 38600 to 38700...\n",
      "Saved batch 38600–38700 in 22.3 sec. Total done: 38700\n",
      "Processing movies 38700 to 38800...\n",
      "Saved batch 38700–38800 in 18.5 sec. Total done: 38800\n",
      "Processing movies 38800 to 38900...\n",
      "Saved batch 38800–38900 in 18.4 sec. Total done: 38900\n",
      "Processing movies 38900 to 39000...\n",
      "Saved batch 38900–39000 in 18.7 sec. Total done: 39000\n",
      "Processing movies 39000 to 39100...\n",
      "Saved batch 39000–39100 in 20.4 sec. Total done: 39100\n",
      "Processing movies 39100 to 39200...\n",
      "Saved batch 39100–39200 in 22.5 sec. Total done: 39200\n",
      "Processing movies 39200 to 39300...\n",
      "Saved batch 39200–39300 in 16.6 sec. Total done: 39300\n",
      "Processing movies 39300 to 39400...\n",
      "Saved batch 39300–39400 in 17.6 sec. Total done: 39400\n",
      "Processing movies 39400 to 39500...\n",
      "Saved batch 39400–39500 in 16.9 sec. Total done: 39500\n",
      "Processing movies 39500 to 39600...\n",
      "Saved batch 39500–39600 in 16.7 sec. Total done: 39600\n",
      "Processing movies 39600 to 39700...\n",
      "Saved batch 39600–39700 in 16.6 sec. Total done: 39700\n",
      "Processing movies 39700 to 39800...\n",
      "Saved batch 39700–39800 in 16.5 sec. Total done: 39800\n",
      "Processing movies 39800 to 39900...\n",
      "Saved batch 39800–39900 in 16.8 sec. Total done: 39900\n",
      "Processing movies 39900 to 40000...\n",
      "Saved batch 39900–40000 in 16.6 sec. Total done: 40000\n",
      "Processing movies 40000 to 40100...\n",
      "Saved batch 40000–40100 in 16.5 sec. Total done: 40100\n",
      "Processing movies 40100 to 40200...\n",
      "Saved batch 40100–40200 in 16.0 sec. Total done: 40200\n",
      "Processing movies 40200 to 40300...\n",
      "Saved batch 40200–40300 in 16.7 sec. Total done: 40300\n",
      "Processing movies 40300 to 40400...\n",
      "Saved batch 40300–40400 in 16.2 sec. Total done: 40400\n",
      "Processing movies 40400 to 40500...\n",
      "Saved batch 40400–40500 in 16.2 sec. Total done: 40500\n",
      "Processing movies 40500 to 40600...\n",
      "Saved batch 40500–40600 in 16.5 sec. Total done: 40600\n",
      "Processing movies 40600 to 40700...\n",
      "Saved batch 40600–40700 in 15.9 sec. Total done: 40700\n",
      "Processing movies 40700 to 40800...\n",
      "Saved batch 40700–40800 in 16.2 sec. Total done: 40800\n",
      "Processing movies 40800 to 40900...\n",
      "Saved batch 40800–40900 in 16.5 sec. Total done: 40900\n",
      "Processing movies 40900 to 41000...\n",
      "Saved batch 40900–41000 in 16.7 sec. Total done: 41000\n",
      "Processing movies 41000 to 41100...\n",
      "Saved batch 41000–41100 in 16.1 sec. Total done: 41100\n",
      "Processing movies 41100 to 41200...\n",
      "Saved batch 41100–41200 in 16.5 sec. Total done: 41200\n",
      "Processing movies 41200 to 41300...\n",
      "Saved batch 41200–41300 in 16.7 sec. Total done: 41300\n",
      "Processing movies 41300 to 41400...\n",
      "Saved batch 41300–41400 in 16.2 sec. Total done: 41400\n",
      "Processing movies 41400 to 41500...\n",
      "Saved batch 41400–41500 in 16.2 sec. Total done: 41500\n",
      "Processing movies 41500 to 41600...\n",
      "Saved batch 41500–41600 in 16.1 sec. Total done: 41600\n",
      "Processing movies 41600 to 41700...\n",
      "Saved batch 41600–41700 in 16.2 sec. Total done: 41700\n",
      "Processing movies 41700 to 41800...\n",
      "Saved batch 41700–41800 in 16.3 sec. Total done: 41800\n",
      "Processing movies 41800 to 41900...\n",
      "Saved batch 41800–41900 in 15.5 sec. Total done: 41900\n",
      "Processing movies 41900 to 42000...\n",
      "Saved batch 41900–42000 in 15.9 sec. Total done: 42000\n",
      "Processing movies 42000 to 42100...\n",
      "Saved batch 42000–42100 in 15.6 sec. Total done: 42100\n",
      "Processing movies 42100 to 42200...\n",
      "Saved batch 42100–42200 in 16.1 sec. Total done: 42200\n",
      "Processing movies 42200 to 42300...\n",
      "Saved batch 42200–42300 in 16.4 sec. Total done: 42300\n",
      "Processing movies 42300 to 42400...\n",
      "Saved batch 42300–42400 in 16.3 sec. Total done: 42400\n",
      "Processing movies 42400 to 42500...\n",
      "Saved batch 42400–42500 in 16.4 sec. Total done: 42500\n",
      "Processing movies 42500 to 42600...\n",
      "Saved batch 42500–42600 in 16.0 sec. Total done: 42600\n",
      "Processing movies 42600 to 42700...\n",
      "Saved batch 42600–42700 in 16.0 sec. Total done: 42700\n",
      "Processing movies 42700 to 42800...\n",
      "Saved batch 42700–42800 in 16.1 sec. Total done: 42800\n",
      "Processing movies 42800 to 42900...\n",
      "Saved batch 42800–42900 in 15.7 sec. Total done: 42900\n",
      "Processing movies 42900 to 43000...\n",
      "Saved batch 42900–43000 in 16.1 sec. Total done: 43000\n",
      "Processing movies 43000 to 43100...\n",
      "Saved batch 43000–43100 in 16.3 sec. Total done: 43100\n",
      "Processing movies 43100 to 43200...\n",
      "Saved batch 43100–43200 in 17.8 sec. Total done: 43200\n",
      "Processing movies 43200 to 43300...\n",
      "Saved batch 43200–43300 in 16.6 sec. Total done: 43300\n",
      "Processing movies 43300 to 43400...\n",
      "Saved batch 43300–43400 in 17.2 sec. Total done: 43400\n",
      "Processing movies 43400 to 43500...\n",
      "Saved batch 43400–43500 in 17.8 sec. Total done: 43500\n",
      "Processing movies 43500 to 43600...\n",
      "Saved batch 43500–43600 in 17.1 sec. Total done: 43600\n",
      "Processing movies 43600 to 43700...\n",
      "Saved batch 43600–43700 in 17.6 sec. Total done: 43700\n",
      "Processing movies 43700 to 43800...\n",
      "Saved batch 43700–43800 in 17.3 sec. Total done: 43800\n",
      "Processing movies 43800 to 43900...\n",
      "Saved batch 43800–43900 in 16.2 sec. Total done: 43900\n",
      "Processing movies 43900 to 44000...\n",
      "Saved batch 43900–44000 in 17.5 sec. Total done: 44000\n",
      "Processing movies 44000 to 44100...\n",
      "Saved batch 44000–44100 in 17.4 sec. Total done: 44100\n",
      "Processing movies 44100 to 44200...\n",
      "Saved batch 44100–44200 in 17.4 sec. Total done: 44200\n",
      "Processing movies 44200 to 44300...\n",
      "Saved batch 44200–44300 in 17.4 sec. Total done: 44300\n",
      "Processing movies 44300 to 44400...\n",
      "Saved batch 44300–44400 in 17.4 sec. Total done: 44400\n",
      "Processing movies 44400 to 44500...\n",
      "Saved batch 44400–44500 in 17.5 sec. Total done: 44500\n",
      "Processing movies 44500 to 44600...\n",
      "Saved batch 44500–44600 in 17.4 sec. Total done: 44600\n",
      "Processing movies 44600 to 44700...\n",
      "Saved batch 44600–44700 in 17.4 sec. Total done: 44700\n",
      "Processing movies 44700 to 44800...\n",
      "Saved batch 44700–44800 in 17.3 sec. Total done: 44800\n",
      "Processing movies 44800 to 44880...\n",
      "Saved batch 44800–44880 in 14.2 sec. Total done: 44880\n",
      "\n",
      "All batches completed. Results saved to: evaluation_precision_mrr.csv\n"
     ]
    }
   ],
   "source": [
    "# CONFIG\n",
    "BATCH_SIZE = 100\n",
    "TOP_K = 10\n",
    "SAVE_PATH = \"evaluation_precision_mrr.csv\"\n",
    "\n",
    "# Load data\n",
    "model_df = pd.read_csv(\"model_df.csv\")  # Already preprocessed\n",
    "final_matrix = sparse.load_npz(\"final_matrix_tfidf.npz\")\n",
    "\n",
    "# Load genres and language one-hots if needed\n",
    "if 'original_language' not in model_df.columns:\n",
    "    model_df['original_language'] = pd.read_csv(\"language_encoded.csv\").idxmax(axis=1)\n",
    "\n",
    "# is_relevant function (without recall dependency)\n",
    "def is_relevant(query_row, candidate_row):\n",
    "    \"\"\"\n",
    "    Determines if a candidate movie is relevant to a query movie based on shared metadata.\n",
    "\n",
    "    Relevance is defined by the following conditions:\n",
    "    - Must have the same original language.\n",
    "    - OR same director.\n",
    "    - OR at least two shared genres.\n",
    "    - OR at least one shared actor.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    query_row : pd.Series\n",
    "        Metadata for the query movie.\n",
    "\n",
    "    candidate_row : pd.Series\n",
    "        Metadata for the candidate movie.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    bool\n",
    "        True if the candidate is relevant to the query, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "    if query_row['original_language'] != candidate_row['original_language']:\n",
    "        return False\n",
    "    if query_row['director_clean'] == candidate_row['director_clean']:\n",
    "        return True\n",
    "    query_genres = set(eval(query_row['genres_clean'])) if isinstance(query_row['genres_clean'], str) else set()\n",
    "    candidate_genres = set(eval(candidate_row['genres_clean'])) if isinstance(candidate_row['genres_clean'], str) else set()\n",
    "    if len(query_genres.intersection(candidate_genres)) >= 2:\n",
    "        return True\n",
    "    query_actors = set(query_row['actors_clean'].split())\n",
    "    candidate_actors = set(candidate_row['actors_clean'].split())\n",
    "    if len(query_actors.intersection(candidate_actors)) >= 1:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def evaluate_one_movie(i):\n",
    "    \"\"\"\n",
    "    Computes Precision@K and MRR@K for a single movie based on cosine similarity.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    i : int\n",
    "        Index of the query movie in the TF-IDF matrix.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (movie_index, movie_title, precision@K, mrr@K)\n",
    "        or (movie_index, movie_title, None, None) if an error occurs.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        query_vec = final_matrix[i]\n",
    "        sims = cosine_similarity(query_vec, final_matrix).flatten()\n",
    "        sims[i] = -1  # exclude itself\n",
    "        top_indices = np.argsort(sims)[-TOP_K:][::-1]\n",
    "        query_row = model_df.iloc[i]\n",
    "        relevant_found = 0\n",
    "        reciprocal_rank = 0.0\n",
    "\n",
    "        for rank, idx in enumerate(top_indices, start=1):\n",
    "            candidate_row = model_df.iloc[idx]\n",
    "            if is_relevant(query_row, candidate_row):\n",
    "                relevant_found += 1\n",
    "                if reciprocal_rank == 0.0:\n",
    "                    reciprocal_rank = 1 / rank\n",
    "\n",
    "        precision = relevant_found / TOP_K\n",
    "        return i, model_df.iloc[i]['title'], precision, reciprocal_rank\n",
    "\n",
    "    except Exception as e:\n",
    "        return i, model_df.iloc[i]['title'], None, None\n",
    "\n",
    "def save_batch_results(batch_results, filepath):\n",
    "    \"\"\"\n",
    "    Appends a batch of evaluation results to a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    batch_results : list of tuples\n",
    "        Each tuple contains (index, title, precision@K, mrr@K).\n",
    "\n",
    "    filepath : str\n",
    "        Path to the CSV file where results will be saved.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.DataFrame(batch_results, columns=[\"index\", \"title\", f\"precision@{TOP_K}\", f\"mrr@{TOP_K}\"])\n",
    "    if os.path.exists(filepath):\n",
    "        df.to_csv(filepath, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filepath, index=False)\n",
    "\n",
    "# Check already processed indices\n",
    "if os.path.exists(SAVE_PATH):\n",
    "    existing = pd.read_csv(SAVE_PATH)\n",
    "    processed_indices = set(existing['index'])\n",
    "else:\n",
    "    processed_indices = set()\n",
    "\n",
    "# Batch loop\n",
    "total_movies = len(model_df)\n",
    "for start in range(0, total_movies, BATCH_SIZE):\n",
    "    end = min(start + BATCH_SIZE, total_movies)\n",
    "    batch_indices = [i for i in range(start, end) if i not in processed_indices]\n",
    "\n",
    "    if not batch_indices:\n",
    "        print(f\"Skipping batch {start}–{end}, already done.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing movies {start} to {end}...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    batch_results = Parallel(n_jobs=-1)(\n",
    "        delayed(evaluate_one_movie)(i) for i in batch_indices\n",
    "    )\n",
    "\n",
    "    batch_results = [res for res in batch_results if res[2] is not None]  # Filter failed ones\n",
    "    save_batch_results(batch_results, SAVE_PATH)\n",
    "\n",
    "    print(f\"Saved batch {start}–{end} in {time.time() - start_time:.1f} sec. Total done: {start + len(batch_results)}\")\n",
    "\n",
    "print(\"\\nAll batches completed. Results saved to:\", SAVE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04283701-0229-48f4-9bbc-81880e054881",
   "metadata": {},
   "source": [
    "**Notes:**\n",
    "- You can pause and resume the script anytime. It skips already processed indices.\n",
    "- If you want to test quickly, try `BATCH_SIZE = 10`.\n",
    "- You can adjust `TOP_K = 5` or `20` easily."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1670ea3-7519-4357-b542-b31a985bc3e7",
   "metadata": {},
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "batch_results = Parallel(n_jobs=-1)(\n",
    "    delayed(evaluate_one_movie)(i) for i in batch_indices\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03f74ef-621d-416d-a0c9-7ab1e0fbb630",
   "metadata": {},
   "source": [
    "The code above:\n",
    "- `delayed(...)` wraps that function so it can be executed in parallel.\n",
    "\n",
    "`Parallel(n_jobs=-1)` tells it to:\n",
    "- Use all available CPU cores on our machine (based on the number of threads available on a laptop or pc).\n",
    "- Distribute the evaluation across those cores automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2328a920-4951-462b-bda3-7487c46a2929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Evaluation over 44880 movies:\n",
      "Mean Precision@10: 0.7796\n",
      "Mean MRR@10: 0.9016\n"
     ]
    }
   ],
   "source": [
    "# Calculate Final Averages on Precision and MRR\n",
    "\n",
    "# Load your results\n",
    "results = pd.read_csv(\"evaluation_precision_mrr.csv\")\n",
    "\n",
    "# Drop any incomplete or failed entries (optional safety)\n",
    "results = results.dropna(subset=[\"precision@10\", \"mrr@10\"])\n",
    "\n",
    "# Compute the averages\n",
    "mean_precision = results[\"precision@10\"].mean()\n",
    "mean_mrr = results[\"mrr@10\"].mean()\n",
    "\n",
    "print(f\"Final Evaluation over {len(results)} movies:\")\n",
    "print(f\"Mean Precision@10: {mean_precision:.4f}\")\n",
    "print(f\"Mean MRR@10: {mean_mrr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c602fe67-4988-4ec7-b30b-188ed4ad8307",
   "metadata": {},
   "source": [
    "-----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9fe5b-c012-4583-9c40-9cf64ade5892",
   "metadata": {},
   "source": [
    "### 6. Performance Evaluation (User-Profile-Based Recommendation Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8cbaf5-b031-400e-a4bb-5922d3f47422",
   "metadata": {},
   "source": [
    "This evaluation method is not our primary objective, and it is merely experimental because evaluation using this approach usually requires a massive database of users' ratings to capture each user's preference and make a user profile. However, it is impossible for each user to see and record enough movie ratings to fulfill the requirement of such an evaluation successfully. To address this issue, scientists offered matrix factorization as a very effective method to replace this approach.\n",
    "\n",
    "Recommending items to a customer similar to previous items rated highly by the customer. Based on the items a user likes, we can create a profile to suggest similar movies they may enjoy. So, we need to create a profile for items as well (or a vector of features), which has already been done using the TF-IDF Vectorizer. After making an item's profile, we need to create a user profile. A user profile is an aggregate of items, like a weighted average of rated item profiles. Having both the item profile and the user profile will allow us to estimate the similarity of vectors between the user profile and the item profile.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b63a77d-c166-496a-a302-df60c5f6607f",
   "metadata": {},
   "source": [
    "**Issues with this approach:**\n",
    "- **Over Specialization**\n",
    "  - It never suggests items outside of users' preferences\n",
    "  - People might have multiple interests, and limited knowledge of users' taste (of movies they have rated) is not enough to capture their preferences.\n",
    "  - Unlike the collaborative filtering approach, we are unable to benefit from the quality judgments of other users\n",
    "- **New Users**\n",
    "   - How can we build a user profile for new users?\n",
    "   - That is why we need the previous approach (only based on item profiles), where we can suggest items based on the content of other items.\n",
    "   - For instance, when you join Netflix, it asks you to pick three movies or series that you like; otherwise, you cannot skip the page."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cceaf8b-6f9e-4510-a5fa-27c91dc09825",
   "metadata": {},
   "source": [
    "#### 6.1. Building User Profiles\n",
    "\n",
    "Here, we create a personalized vector for each user using the ratings they gave to movies, a weighted average of the corresponding item feature vectors. The code below:\n",
    "- Lops over each user.\n",
    "- Builds a normalized user profile vector.\n",
    "- Saves it as user_{user_id}.npz in a folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d268316c-fb7f-4978-9e01-0a4415d66159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "model_df = pd.read_csv('./data/model_ready_movie_data.csv')\n",
    "final_matrix = sparse.load_npz('final_matrix_tfidf.npz')\n",
    "# Load full ratings dataset\n",
    "ratings = pd.read_csv('./data/filtered_ratings.csv')\n",
    "\n",
    "# Count how many ratings each user has\n",
    "user_counts = ratings['userId'].value_counts()\n",
    "\n",
    "# Keep only users with at least 200 ratings (Because we want enough movies with diverse ratings to be available)\n",
    "eligible_users = user_counts[user_counts >= 200].index\n",
    "\n",
    "# Filter ratings dataframe to include only those users\n",
    "ratings = ratings[ratings['userId'].isin(eligible_users)]\n",
    "\n",
    "# Make sure 'id' is available\n",
    "model_df['id'] = df['id']\n",
    "ratings['movieId'] = ratings['movieId'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "625bb207-3d31-4ba8-abd3-5c7d635f5acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building user profiles: 100%|██████████| 10277/10277 [04:42<00:00, 36.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build mapping from movie ID to index in final_matrix\n",
    "movie_id_to_index = {mid: idx for idx, mid in enumerate(model_df['id'])}\n",
    "\n",
    "# Output directory to save user profiles\n",
    "os.makedirs('./user_profiles200', exist_ok=True)\n",
    "\n",
    "def build_user_profile(user_ratings):\n",
    "    \"\"\"\n",
    "    Build a sparse user profile vector as a weighted average of item vectors,\n",
    "    using all ratings (positive and negative).\n",
    "    \"\"\"\n",
    "    indices = [movie_id_to_index.get(mid) for mid in user_ratings['movieId'] if mid in movie_id_to_index]\n",
    "\n",
    "    if not indices:\n",
    "        return None\n",
    "\n",
    "    vectors = final_matrix[indices]\n",
    "    ratings = user_ratings['rating'].values[:len(indices)]\n",
    "\n",
    "    # Weighted sum of vectors\n",
    "    weighted_vectors = vectors.multiply(ratings[:, np.newaxis])\n",
    "    profile_vector = weighted_vectors.sum(axis=0)\n",
    "\n",
    "    # Convert np.matrix to sparse CSR matrix\n",
    "    profile_vector = sparse.csr_matrix(profile_vector)\n",
    "\n",
    "    # Normalize\n",
    "    profile_vector = normalize(profile_vector)\n",
    "\n",
    "    return profile_vector\n",
    "\n",
    "# Process and save each user\n",
    "unique_users = ratings['userId'].unique()\n",
    "\n",
    "for user_id in tqdm(unique_users, desc=\"Building user profiles\"):\n",
    "    user_ratings = ratings[ratings['userId'] == user_id]\n",
    "    user_vector = build_user_profile(user_ratings)\n",
    "\n",
    "    if user_vector is not None:\n",
    "        sparse.save_npz(f'./user_profiles/user_{user_id}.npz', user_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f9eb8c-33e5-4599-8b47-ea248e9a624f",
   "metadata": {},
   "source": [
    "#### 6.3. Generating Recommendations + Evaluating (Precision@K and MRR@K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aa5c2d-d725-4a01-802a-faae2d97c3fd",
   "metadata": {},
   "source": [
    "So, for each user, we follow these steps:\n",
    "1. Split their ratings into train/test (e.g. 80/20).\n",
    "2. Build user profile from training ratings (already done).\n",
    "3. Predict similarity scores between the user profile and each test movie.\n",
    "4. Rank test items by similarity.\n",
    "\n",
    "5. Evaluate:\n",
    "  - Precision@K: Proportion of top-K movies rated ≥ 4\n",
    "  - MRR@K: Reciprocal rank of the first relevant (rated ≥ 4) item in top-K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d103575-0aac-4b12-9e69-3c7d8ba1c935",
   "metadata": {},
   "source": [
    "#### 6.4. Per-User Train/Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a8c0b8-a3c4-4207-939b-ee687f962fa1",
   "metadata": {},
   "source": [
    "We’ll split each user’s ratings into:\n",
    "- Training set (80%) → used to build profile (already done)\n",
    "- Test set (20%) → used for evaluation\n",
    "\n",
    "To compute Precision@K and MRR@K meaningfully for values like K = 5, 10, 20, we must ensure that each user's test set has at least 30 relevant (rating ≥ 4.0) items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7a6f2a0-d2f7-419e-b490-3d85c5ea4310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting ratings: 100%|██████████| 10277/10277 [00:53<00:00, 191.10it/s]\n"
     ]
    }
   ],
   "source": [
    "RELEVANT_RATING = 4.0\n",
    "MIN_RELEVANT_IN_TEST = 30\n",
    "\n",
    "user_train_test_split = {}\n",
    "\n",
    "for user_id in tqdm(ratings['userId'].unique(), desc=\"Splitting ratings\"):\n",
    "    user_data = ratings[ratings['userId'] == user_id].sort_values('timestamp')\n",
    "\n",
    "    if len(user_data) < 50:\n",
    "        continue  # basic total check\n",
    "\n",
    "    # 80/20 split\n",
    "    train, test = train_test_split(user_data, test_size=0.2, random_state=42)\n",
    "\n",
    "    # We keep the entire test set (mixed ratings)\n",
    "    # But include users with ≥ 30 relevant items in test set\n",
    "    if (test['rating'] >= RELEVANT_RATING).sum() >= MIN_RELEVANT_IN_TEST:\n",
    "        user_train_test_split[user_id] = (train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806e1a7a-a6aa-47d9-902d-6dd6a505181d",
   "metadata": {},
   "source": [
    "#### 6.5. Scoring Test Items Using Cosine Similarity\n",
    "\n",
    "Use each user's saved profile to score all items in their test set via cosine similarity, then rank them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08f62f3-39f3-4181-bdef-51f6ebf60d20",
   "metadata": {},
   "source": [
    "So, we get ranked recommendations for a user:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b44cd9d-8ee0-44a7-8b84-32ac6f4cdf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_recommendation_scores(user_id, test_df):\n",
    "    \"\"\"\n",
    "    Given a user's ID and their test ratings, return:\n",
    "    - test movie indices\n",
    "    - scores from cosine similarity\n",
    "    - actual ratings\n",
    "    \"\"\"\n",
    "    profile_path = f'./user_profiles200/user_{user_id}.npz'\n",
    "    if not os.path.exists(profile_path):\n",
    "        return None  # skip users with no profile\n",
    "\n",
    "    user_vector = sparse.load_npz(profile_path)\n",
    "\n",
    "    # Get item indices in the test set\n",
    "    valid_rows = []\n",
    "    actual_ratings = []\n",
    "\n",
    "    for _, row in test_df.iterrows():\n",
    "        movie_id = row['movieId']\n",
    "        rating = row['rating']\n",
    "        if movie_id in movie_id_to_index:\n",
    "            idx = movie_id_to_index[movie_id]\n",
    "            valid_rows.append(idx)\n",
    "            actual_ratings.append(rating)\n",
    "\n",
    "    if not valid_rows:\n",
    "        return None\n",
    "\n",
    "    test_vectors = final_matrix[valid_rows]\n",
    "    scores = cosine_similarity(user_vector, test_vectors).flatten()\n",
    "\n",
    "    return list(zip(valid_rows, scores, actual_ratings))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5db53f-659a-43c4-af2d-9e636c076849",
   "metadata": {},
   "source": [
    "#### 6.6. Compute Precision@K and MRR@K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25c5a89-c88d-4b92-8d61-496640732e22",
   "metadata": {},
   "source": [
    "**Precision@K:**\n",
    "- Proportion of top-K recommended movies that have actual rating ≥ 4.0.\n",
    "\n",
    "**MRR@K (Mean Reciprocal Rank):**\n",
    "- 1 / rank of the first relevant (rating ≥ 4.0) item among top K, or 0 if none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c2d176d-8f61-4995-a830-63ca9fa8bf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_precision_mrr_k(recommendations, k, relevant_threshold=4.0):\n",
    "    \"\"\"\n",
    "    recommendations: list of (movie_idx, score, actual_rating), sorted by score DESC\n",
    "    Returns: precision@k, mrr@k\n",
    "    \"\"\"\n",
    "    top_k = recommendations[:k]\n",
    "    relevant_flags = [rating >= relevant_threshold for _, _, rating in top_k]\n",
    "\n",
    "    # Precision@K\n",
    "    precision = sum(relevant_flags) / k\n",
    "\n",
    "    # MRR@K\n",
    "    mrr = 0\n",
    "    for rank, is_relevant in enumerate(relevant_flags, start=1):\n",
    "        if is_relevant:\n",
    "            mrr = 1.0 / rank\n",
    "            break\n",
    "\n",
    "    return precision, mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4863f152-b101-4d54-a4b6-85494c8f6f51",
   "metadata": {},
   "source": [
    "#### 6.7. Evaluate Across All Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac3cd1e-7b00-432b-b56c-57ef0d41366f",
   "metadata": {},
   "source": [
    "Now, we evaluate across all users. This code:\n",
    "\n",
    "- Loads the test set for each user\n",
    "- Loads their profile vector\n",
    "- Ranks test items by similarity\n",
    "- Computes Precision@5/10/20 and MRR@5/10/20\n",
    "- Averages them across users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93116943-81bd-49af-8a49-96fd0622b99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating users: 100%|██████████| 3989/3989 [00:31<00:00, 125.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store evaluation metrics for each user\n",
    "precision_at_5 = []\n",
    "precision_at_10 = []\n",
    "precision_at_20 = []\n",
    "\n",
    "mrr_at_5 = []\n",
    "mrr_at_10 = []\n",
    "mrr_at_20 = []\n",
    "\n",
    "# Iterate over each user and their corresponding test set\n",
    "for user_id, (_, test_df) in tqdm(user_train_test_split.items(), desc=\"Evaluating users\"):\n",
    "\n",
    "    # Get similarity scores between the user profile and each movie in the user's test set\n",
    "    scores = get_user_recommendation_scores(user_id, test_df)\n",
    "    \n",
    "    if not scores:\n",
    "        continue  # skip users with no test items\n",
    "\n",
    "    # Sort test items by similarity score in descending order\n",
    "    ranked = sorted(scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Evaluate Precision@K and MRR@K for K = 5, 10, 20\n",
    "    p5, mrr5 = evaluate_precision_mrr_k(ranked, k=5)\n",
    "    p10, mrr10 = evaluate_precision_mrr_k(ranked, k=10)\n",
    "    p20, mrr20 = evaluate_precision_mrr_k(ranked, k=20)\n",
    "\n",
    "    precision_at_5.append(p5)\n",
    "    precision_at_10.append(p10)\n",
    "    precision_at_20.append(p20)\n",
    "\n",
    "    mrr_at_5.append(mrr5)\n",
    "    mrr_at_10.append(mrr10)\n",
    "    mrr_at_20.append(mrr20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "839891a1-04f9-4115-a315-80863a21106b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "Precision@5:  0.5994\n",
      "Precision@10: 0.5837\n",
      "Precision@20: 0.5796\n",
      "MRR@5:        0.7624\n",
      "MRR@10:       0.7656\n",
      "MRR@20:       0.7658\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation Results:\")\n",
    "print(f\"Precision@5:  {np.mean(precision_at_5):.4f}\")\n",
    "print(f\"Precision@10: {np.mean(precision_at_10):.4f}\")\n",
    "print(f\"Precision@20: {np.mean(precision_at_20):.4f}\")\n",
    "\n",
    "print(f\"MRR@5:        {np.mean(mrr_at_5):.4f}\")\n",
    "print(f\"MRR@10:       {np.mean(mrr_at_10):.4f}\")\n",
    "print(f\"MRR@20:       {np.mean(mrr_at_20):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
